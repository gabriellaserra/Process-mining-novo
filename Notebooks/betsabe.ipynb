{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 42\n",
      "Number of cases: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pandas.read_csv(file_path, sep=';')\n",
    "    num_events = len(event_log) # numero de eventos (fases que a pessoa vai passar)\n",
    "    num_cases = len(event_log.case_id.unique()) # numero de casos (numero de pessoas)\n",
    "    print(\"Number of events: {}\\nNumber of cases: {}\".format(num_events, num_cases))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start activities: {'register request': 6}\n",
      "End activities: {'reject request': 3, 'pay compensation': 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pm4py\n",
    "\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pandas.read_csv(file_path, sep=';') # carregamento do log de eventos\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    # ^transforma a tabela de dados de eventos em um formato que pode ser usado por qualquer algoritmo de mineração de processos em pm4py\n",
    "    # ^cria uma cópia do log de eventos de entrada e renomeia as colunas atribuídas para nomes de colunas padronizados usados ​​em pm4py\n",
    "    start_activities = pm4py.get_start_activities(event_log) # pega as atividades que ocorrem primeiro no log de eventos\n",
    "    end_activities = pm4py.get_end_activities(event_log) # pega as atividades que ocorrem por último no log de eventos\n",
    "    print(\"Start activities: {}\\nEnd activities: {}\".format(start_activities, end_activities))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo de importação de arquivos .xes\n",
    "import pm4py\n",
    "def import_xes(file_path):\n",
    "    event_log = pm4py.read_xes(file_path)\n",
    "    start_activities = pm4py.get_start_activities(event_log) # pega as atividades que ocorrem primeiro no log de eventos\n",
    "    end_activities = pm4py.get_end_activities(event_log) # pega as atividades que ocorrem por último no log de eventos\n",
    "    print(\"Start activities: {}\\nEnd activities: {}\".format(start_activities, end_activities))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_xes(\"C:/Users/demo/Downloads/running-example.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armazenando um quadro de dados (log de eventos) do Pandas como um arquivo csv\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    event_log = pm4py.format_dataframe(pd.read_csv('C:/Users/demo/Downloads/running-example.csv', sep=';'), case_id='case_id',\n",
    "    activity_key='activity', timestamp_key='timestamp') # lendo um quadro de dados do panda\n",
    "    event_log.to_csv('C:/Users/demo/Desktop/running-example-exported.csv') # convertendo para um arquivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    event_log = pm4py.read_xes('C:/Users/demo/Downloads/running-example.xes') # arquivo XES que será exportado\n",
    "    df = pm4py.convert_to_dataframe(event_log) # convertendo as informações lidas para um quadro de dados\n",
    "    df.to_csv('C:/Users/demo/Desktop/running-example-exported.csv') # arquivo CSV que vai receber a importação \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 6/6 [00:00<00:00, 5247.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start activities: {'register request': 6}\n",
      "End activities: {'reject request': 3, 'pay compensation': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# carregando um arquivo .xes\n",
    "def import_xes(file_path):\n",
    "    event_log = pm4py.read_xes(file_path)\n",
    "    start_activities = pm4py.get_start_activities(event_log)\n",
    "    end_activities = pm4py.get_end_activities(event_log)\n",
    "    print(\"Start activities: {}\\nEnd activities: {}\".format(start_activities, end_activities))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_xes(\"Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 6/6 [00:00<00:00, 4895.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testando filtros, usando arquivos .xes\n",
    "import pm4py\n",
    "import datetime as dt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log = pm4py.read_xes('Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.xes')\n",
    "\n",
    "    # filtra as atividades que ocorrem no começo de um rastreamento\n",
    "    filtered = pm4py.filter_start_activities(log, {'register request'})\n",
    "\n",
    "    \n",
    "    filtered = pm4py.filter_start_activities(log, {'register request TYPO!'})\n",
    "\n",
    "    # filtra as atividades que ocorrem no final de um rastreamento\n",
    "    filtered = pm4py.filter_end_activities(log, {'pay compensation'})\n",
    "\n",
    "    filtered = pm4py.filter_event_attribute_values(log, 'org:resource', {'Pete', 'Mike'})\n",
    "\n",
    "    filtered = pm4py.filter_event_attribute_values(log, 'org:resource', {'Pete', 'Mike'}, level='event')\n",
    "\n",
    "    filtered = pm4py.filter_trace_attribute_values(log, 'concept:name', {'3', '4'})\n",
    "\n",
    "    filtered = pm4py.filter_trace_attribute_values(log, 'concept:name', {'3', '4'}, retain=False)\n",
    "\n",
    "    filtered = pm4py.filter_variants(log, [\n",
    "        ['register request', 'check ticket', 'examine casually', 'decide', 'pay compensation']])\n",
    "\n",
    "    filtered = pm4py.filter_variants(log, [\n",
    "        ['register request', 'check ticket', 'examine casually', 'decide', 'reject request']])\n",
    "\n",
    "    filtered = pm4py.filter_directly_follows_relation(log, [('check ticket', 'examine casually')])\n",
    "\n",
    "    filtered = pm4py.filter_eventually_follows_relation(log, [('examine casually', 'reject request')])\n",
    "\n",
    "    filtered = pm4py.filter_time_range(log, dt.datetime(2010, 12, 30), dt.datetime(2010, 12, 31), mode='events')\n",
    "\n",
    "    filtered = pm4py.filter_time_range(log, dt.datetime(2010, 12, 30), dt.datetime(2010, 12, 31),\n",
    "                                       mode='traces_contained')\n",
    "\n",
    "    filtered = pm4py.filter_time_range(log, dt.datetime(2010, 12, 30), dt.datetime(2010, 12, 31),mode='traces_intersecting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4]\n",
      "['14:32:0', '15:6:0', '16:34:0', '9:18:0', '12:18:0', '13:6:0', '11:43:0', '9:55:0', '10:45:0', '11:32:0', '12:12:0', '14:16:0', '11:22:0', '12:5:0', '11:2:0', '10:6:0', '15:12:0', '11:18:0', '14:24:0', '15:2:0', '16:6:0', '16:22:0', '16:52:0', '11:47:0', '9:2:0', '10:16:0', '11:22:0', '13:28:0', '16:18:0', '14:33:0', '15:50:0', '11:18:0', '12:48:0', '9:6:0', '11:34:0', '13:12:0', '14:56:0', '15:2:0', '12:6:0', '14:43:0', '12:2:0', '15:44:0']\n"
     ]
    }
   ],
   "source": [
    "# filtrando a hora dos casos\n",
    "import pandas\n",
    "import pm4py\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log = pandas.read_csv('Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv', sep = ';')\n",
    "    # listaAtividades = log['activity']\n",
    "    listaPessoas = list(log.case_id)\n",
    "    listaHoras = list(log.timestamp)\n",
    "    listaHora2 = []\n",
    "    for hora in listaHora:\n",
    "        dataConvertida = datetime.datetime.strptime(hora, \"%Y-%m-%d %H:%M:%S%z\")\n",
    "        listaHora2.append(f'{dataConvertida.hour}:{dataConvertida.minute}:{dataConvertida.second}')\n",
    "    # listaHora = pd.to_datetime(log['timestamp']).dt.strftime('%H:%M:%S')\n",
    "    print(listaPessoas)\n",
    "    print(listaHora2)\n",
    "    # print(listaAtividades)\n",
    "    # listaHora = pd.to_datetime(log['time:timestamp']).dt.strftime('%H:%M:%S')\n",
    "    # for (i, atividade) in enumerate(listaAtividades):\n",
    "    #     print('atividade: ',atividade)\n",
    "    #     print('hora: ',listaHora[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: (['register request', '2010-12-30 14:32:00+01:00'], ['examine casually', '2010-12-30 15:06:00+01:00'], ['check ticket', '2010-12-30 16:34:00+01:00'], ['decide', '2011-01-06 09:18:00+01:00'], ['reinitiate request', '2011-01-06 12:18:00+01:00'], ['examine thoroughly', '2011-01-06 13:06:00+01:00'], ['check ticket', '2011-01-08 11:43:00+01:00'], ['decide', '2011-01-09 09:55:00+01:00'], ['pay compensation', '2011-01-15 10:45:00+01:00']), 2: (['register request', '2010-12-30 11:32:00+01:00'], ['check ticket', '2010-12-30 12:12:00+01:00'], ['examine casually', '2010-12-30 14:16:00+01:00'], ['decide', '2011-01-05 11:22:00+01:00'], ['pay compensation', '2011-01-08 12:05:00+01:00']), 1: (['register request', '2010-12-30 11:02:00+01:00'], ['examine thoroughly', '2010-12-31 10:06:00+01:00'], ['check ticket', '2011-01-05 15:12:00+01:00'], ['decide', '2011-01-06 11:18:00+01:00'], ['reject request', '2011-01-07 14:24:00+01:00']), 6: (['register request', '2011-01-06 15:02:00+01:00'], ['examine casually', '2011-01-06 16:06:00+01:00'], ['check ticket', '2011-01-07 16:22:00+01:00'], ['decide', '2011-01-07 16:52:00+01:00'], ['pay compensation', '2011-01-16 11:47:00+01:00']), 5: (['register request', '2011-01-06 09:02:00+01:00'], ['examine casually', '2011-01-07 10:16:00+01:00'], ['check ticket', '2011-01-08 11:22:00+01:00'], ['decide', '2011-01-10 13:28:00+01:00'], ['reinitiate request', '2011-01-11 16:18:00+01:00'], ['check ticket', '2011-01-14 14:33:00+01:00'], ['examine casually', '2011-01-16 15:50:00+01:00'], ['decide', '2011-01-19 11:18:00+01:00'], ['reinitiate request', '2011-01-20 12:48:00+01:00'], ['examine casually', '2011-01-21 09:06:00+01:00'], ['check ticket', '2011-01-21 11:34:00+01:00'], ['decide', '2011-01-23 13:12:00+01:00'], ['reject request', '2011-01-24 14:56:00+01:00']), 4: (['register request', '2011-01-06 15:02:00+01:00'], ['check ticket', '2011-01-07 12:06:00+01:00'], ['examine thoroughly', '2011-01-08 14:43:00+01:00'], ['decide', '2011-01-09 12:02:00+01:00'], ['reject request', '2011-01-12 15:44:00+01:00'])}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'listaHora' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(dicPessoas)\n\u001b[0;32m     19\u001b[0m listaHora2 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hora \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlistaHora\u001b[49m:\n\u001b[0;32m     21\u001b[0m     dataConvertida \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(hora, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     listaHora2\u001b[38;5;241m.\u001b[39mappend(dataConvertida)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'listaHora' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log = pandas.read_csv('Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv', sep = ';')\n",
    "\n",
    "    listaAtividades = list(log.activity)\n",
    "    listaCasos = list(log.case_id)\n",
    "    listaHoras = list(log.timestamp)\n",
    "    \n",
    "    dicPessoas = {}\n",
    "    for (i,pessoa) in enumerate(listaCasos):\n",
    "        if pessoa in dicPessoas:\n",
    "            dicPessoas[pessoa] += tuple([[listaAtividades[i],listaHoras[i]]])\n",
    "        else:\n",
    "            dicPessoas[pessoa] = tuple([[listaAtividades[i],listaHoras[i]]])\n",
    "    print(dicPessoas)\n",
    "\n",
    "    listaHora2 = []\n",
    "    for hora in listaHora:\n",
    "        dataConvertida = datetime.datetime.strptime(hora, \"%Y-%m-%d %H:%M:%S%z\")\n",
    "        listaHora2.append(dataConvertida)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meu_grafo.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testes do graphviz\n",
    "from graphviz import Digraph\n",
    "\n",
    "# Criar um objeto Digraph (para grafos direcionados)\n",
    "dot = graphviz.Digraph(comment='O Meu Grafo')\n",
    "\n",
    "# Adicionar nós\n",
    "dot.node('A', 'Nó A')\n",
    "dot.node('B', 'Nó B')\n",
    "dot.node('C', 'Nó C')\n",
    "\n",
    "# Adicionar arestas\n",
    "dot.edges(['AB', 'BC', 'CA'])\n",
    "\n",
    "# Salvar o gráfico como um arquivo DOT (opcional)\n",
    "dot.save('meu_grafo.dot')\n",
    "\n",
    "# Gerar uma visualização em PDF\n",
    "dot.render('meu_grafo', format='pdf', cleanup=True)\n",
    "\n",
    "# Gerar uma visualização em outros formatos, como PNG (opcional)\n",
    "dot.render('meu_grafo', format='png', cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process graph saved as 'process_graph.png'\n"
     ]
    }
   ],
   "source": [
    "# código do Caio \n",
    "import pandas as pd\n",
    "import pm4py\n",
    "from graphviz import Digraph\n",
    "\n",
    "def import_csv(file_path):\n",
    "    # Carregar o log de eventos a partir do arquivo CSV\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Converter a coluna 'timestamp' para o formato de data/hora\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "    \n",
    "    # Calcular o tempo gasto em cada ação para todos os pacientes\n",
    "    action_times = {}\n",
    "    for action in event_log['activity'].unique():\n",
    "        action_group = event_log[event_log['activity'] == action]\n",
    "        action_times[action] = action_group['timestamp'].max() - action_group['timestamp'].min()\n",
    "    \n",
    "    # Calcular a média dos tempos em segundos\n",
    "    total_time_seconds = sum(action_times.values(), pd.Timedelta(0)).total_seconds()\n",
    "    num_actions = len(action_times)\n",
    "    if num_actions != 0:\n",
    "        average_time_seconds = total_time_seconds / num_actions\n",
    "    else:\n",
    "        average_time_seconds = 0\n",
    "    \n",
    "    # Converter a média de volta para um objeto Timedelta\n",
    "    average_time = pd.Timedelta(seconds=average_time_seconds)\n",
    "    \n",
    "    # Descobrir o modelo de processo usando o algoritmo Alpha Miner\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    net, initial_marking, final_marking = pm4py.discover_petri_net_alpha(event_log)\n",
    "    \n",
    "    # Criar um objeto Digraph do Graphviz\n",
    "    dot = Digraph(comment='Process Mining', format='png')\n",
    "    \n",
    "    # Adicionar nós ao grafo\n",
    "    for p in net.places:\n",
    "        if p.name in action_times:\n",
    "            # Adicionar tempo médio como rótulo do nó\n",
    "            label = f\"{p.name} (Tempo médio: {action_times[p.name]})\"\n",
    "        else:\n",
    "            label = p.name\n",
    "        dot.node(p.name, label=label)\n",
    "    \n",
    "    # Adicionar transições ao grafo\n",
    "    for t in net.transitions:\n",
    "        dot.node(t.name, shape='rectangle', style='filled', fillcolor='lightblue')\n",
    "    \n",
    "    # Adicionar arestas ao grafo\n",
    "    for arc in net.arcs:\n",
    "        dot.edge(arc.source.name, arc.target.name)\n",
    "    \n",
    "    # Salvar o gráfico em um arquivo\n",
    "    dot.render('process_graph', format='png', cleanup=True)\n",
    "    print(\"Process graph saved as 'process_graph.png'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"C:\\\\Users\\\\betsabenogueira\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\"\n",
    "    import_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
