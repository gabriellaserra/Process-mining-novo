{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 42\n",
      "Number of cases: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pandas.read_csv(file_path, sep=';')\n",
    "    num_events = len(event_log) # numero de eventos (fases que a pessoa vai passar)\n",
    "    num_cases = len(event_log.case_id.unique()) # numero de casos (numero de pessoas)\n",
    "    print(\"Number of events: {}\\nNumber of cases: {}\".format(num_events, num_cases))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start activities: {'register request': 6}\n",
      "End activities: {'reject request': 3, 'pay compensation': 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pm4py\n",
    "\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pandas.read_csv(file_path, sep=';') # carregamento do log de eventos\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    # ^transforma a tabela de dados de eventos em um formato que pode ser usado por qualquer algoritmo de mineração de processos em pm4py\n",
    "    # ^cria uma cópia do log de eventos de entrada e renomeia as colunas atribuídas para nomes de colunas padronizados usados ​​em pm4py\n",
    "    start_activities = pm4py.get_start_activities(event_log) # pega as atividades que ocorrem primeiro no log de eventos\n",
    "    end_activities = pm4py.get_end_activities(event_log) # pega as atividades que ocorrem por último no log de eventos\n",
    "    print(\"Start activities: {}\\nEnd activities: {}\".format(start_activities, end_activities))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo de importação de arquivos .xes\n",
    "import pm4py\n",
    "def import_xes(file_path):\n",
    "    event_log = pm4py.read_xes(file_path)\n",
    "    start_activities = pm4py.get_start_activities(event_log) # pega as atividades que ocorrem primeiro no log de eventos\n",
    "    end_activities = pm4py.get_end_activities(event_log) # pega as atividades que ocorrem por último no log de eventos\n",
    "    print(\"Start activities: {}\\nEnd activities: {}\".format(start_activities, end_activities))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_xes(\"C:/Users/demo/Downloads/running-example.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armazenando um quadro de dados (log de eventos) do Pandas como um arquivo csv\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    event_log = pm4py.format_dataframe(pd.read_csv('C:/Users/demo/Downloads/running-example.csv', sep=';'), case_id='case_id',\n",
    "    activity_key='activity', timestamp_key='timestamp') # lendo um quadro de dados do panda\n",
    "    event_log.to_csv('C:/Users/demo/Desktop/running-example-exported.csv') # convertendo para um arquivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    event_log = pm4py.read_xes('C:/Users/demo/Downloads/running-example.xes') # arquivo XES que será exportado\n",
    "    df = pm4py.convert_to_dataframe(event_log) # convertendo as informações lidas para um quadro de dados\n",
    "    df.to_csv('C:/Users/demo/Desktop/running-example-exported.csv') # arquivo CSV que vai receber a importação \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 6/6 [00:00<00:00, 5247.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start activities: {'register request': 6}\n",
      "End activities: {'reject request': 3, 'pay compensation': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# carregando um arquivo .xes\n",
    "def import_xes(file_path):\n",
    "    event_log = pm4py.read_xes(file_path)\n",
    "    start_activities = pm4py.get_start_activities(event_log)\n",
    "    end_activities = pm4py.get_end_activities(event_log)\n",
    "    print(\"Start activities: {}\\nEnd activities: {}\".format(start_activities, end_activities))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_xes(\"Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 6/6 [00:00<00:00, 4895.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testando filtros, usando arquivos .xes\n",
    "import pm4py\n",
    "import datetime as dt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log = pm4py.read_xes('Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.xes')\n",
    "\n",
    "    # filtra as atividades que ocorrem no começo de um rastreamento\n",
    "    filtered = pm4py.filter_start_activities(log, {'register request'})\n",
    "\n",
    "    \n",
    "    filtered = pm4py.filter_start_activities(log, {'register request TYPO!'})\n",
    "\n",
    "    # filtra as atividades que ocorrem no final de um rastreamento\n",
    "    filtered = pm4py.filter_end_activities(log, {'pay compensation'})\n",
    "\n",
    "    filtered = pm4py.filter_event_attribute_values(log, 'org:resource', {'Pete', 'Mike'})\n",
    "\n",
    "    filtered = pm4py.filter_event_attribute_values(log, 'org:resource', {'Pete', 'Mike'}, level='event')\n",
    "\n",
    "    filtered = pm4py.filter_trace_attribute_values(log, 'concept:name', {'3', '4'})\n",
    "\n",
    "    filtered = pm4py.filter_trace_attribute_values(log, 'concept:name', {'3', '4'}, retain=False)\n",
    "\n",
    "    filtered = pm4py.filter_variants(log, [\n",
    "        ['register request', 'check ticket', 'examine casually', 'decide', 'pay compensation']])\n",
    "\n",
    "    filtered = pm4py.filter_variants(log, [\n",
    "        ['register request', 'check ticket', 'examine casually', 'decide', 'reject request']])\n",
    "\n",
    "    filtered = pm4py.filter_directly_follows_relation(log, [('check ticket', 'examine casually')])\n",
    "\n",
    "    filtered = pm4py.filter_eventually_follows_relation(log, [('examine casually', 'reject request')])\n",
    "\n",
    "    filtered = pm4py.filter_time_range(log, dt.datetime(2010, 12, 30), dt.datetime(2010, 12, 31), mode='events')\n",
    "\n",
    "    filtered = pm4py.filter_time_range(log, dt.datetime(2010, 12, 30), dt.datetime(2010, 12, 31),\n",
    "                                       mode='traces_contained')\n",
    "\n",
    "    filtered = pm4py.filter_time_range(log, dt.datetime(2010, 12, 30), dt.datetime(2010, 12, 31),mode='traces_intersecting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4]\n",
      "['14:32:0', '15:6:0', '16:34:0', '9:18:0', '12:18:0', '13:6:0', '11:43:0', '9:55:0', '10:45:0', '11:32:0', '12:12:0', '14:16:0', '11:22:0', '12:5:0', '11:2:0', '10:6:0', '15:12:0', '11:18:0', '14:24:0', '15:2:0', '16:6:0', '16:22:0', '16:52:0', '11:47:0', '9:2:0', '10:16:0', '11:22:0', '13:28:0', '16:18:0', '14:33:0', '15:50:0', '11:18:0', '12:48:0', '9:6:0', '11:34:0', '13:12:0', '14:56:0', '15:2:0', '12:6:0', '14:43:0', '12:2:0', '15:44:0']\n"
     ]
    }
   ],
   "source": [
    "# filtrando a hora dos casos\n",
    "import pandas\n",
    "import pm4py\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log = pandas.read_csv('Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv', sep = ';')\n",
    "    # listaAtividades = log['activity']\n",
    "    listaPessoas = list(log.case_id)\n",
    "    listaHoras = list(log.timestamp)\n",
    "    listaHora2 = []\n",
    "    for hora in listaHora:\n",
    "        dataConvertida = datetime.datetime.strptime(hora, \"%Y-%m-%d %H:%M:%S%z\")\n",
    "        listaHora2.append(f'{dataConvertida.hour}:{dataConvertida.minute}:{dataConvertida.second}')\n",
    "    # listaHora = pd.to_datetime(log['timestamp']).dt.strftime('%H:%M:%S')\n",
    "    print(listaPessoas)\n",
    "    print(listaHora2)\n",
    "    # print(listaAtividades)\n",
    "    # listaHora = pd.to_datetime(log['time:timestamp']).dt.strftime('%H:%M:%S')\n",
    "    # for (i, atividade) in enumerate(listaAtividades):\n",
    "    #     print('atividade: ',atividade)\n",
    "    #     print('hora: ',listaHora[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pay compensation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m el[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dicIntervalos:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mlen\u001b[39m(listaVazia)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 32\u001b[0m         \u001b[43mdicIntervalos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         dicIntervalos[el[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m listaVazia[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m el[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pay compensation'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from datetime import datetime as dt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log = pandas.read_csv('Y:\\\\git\\\\process ming\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv', sep = ';')\n",
    "\n",
    "    listaAtividades = list(log.activity)\n",
    "    listaCasos = list(log.case_id)\n",
    "    listaHoras = list(log.timestamp)\n",
    "\n",
    "    for (i, hora) in enumerate(listaHoras):\n",
    "        hora = dt.strptime(hora,\"%Y-%m-%d %H:%M:%S%z\")\n",
    "        listaHoras[i] = hora.replace(tzinfo=None)\n",
    "\n",
    "    dicPessoas = {}\n",
    "    for (i,pessoa) in enumerate(listaCasos):\n",
    "        if pessoa in dicPessoas:\n",
    "            dicPessoas[pessoa] += tuple([[listaAtividades[i],listaHoras[i]]])\n",
    "        else:\n",
    "            dicPessoas[pessoa] = tuple([[listaAtividades[i],listaHoras[i]]])\n",
    "\n",
    "    \n",
    "    dicIntervalos = {}\n",
    "\n",
    "    for key in dicPessoas:\n",
    "        listaVazia = []\n",
    "        for atividades in dicPessoas[key]:\n",
    "            listaVazia.append(atividades)\n",
    "        for (i,el) in enumerate(listaVazia):\n",
    "            if el[0] not in dicIntervalos:\n",
    "                if i == (len(listaVazia)-1):\n",
    "                    dicIntervalos[el[0]] == 0\n",
    "                else:\n",
    "                    dicIntervalos[el[0]] = listaVazia[i+1][1] - el[1]\n",
    "            else:\n",
    "                dicIntervalos[el[0]] += listaVazia[i+1][1] - el[1]\n",
    "\n",
    "    print(dicIntervalos)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graphviz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Digraph\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Criar um objeto Digraph (para grafos direcionados)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dot \u001b[38;5;241m=\u001b[39m \u001b[43mgraphviz\u001b[49m\u001b[38;5;241m.\u001b[39mDigraph(comment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO Meu Grafo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Adicionar nós\u001b[39;00m\n\u001b[0;32m      8\u001b[0m dot\u001b[38;5;241m.\u001b[39mnode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNó A\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'graphviz' is not defined"
     ]
    }
   ],
   "source": [
    "# testes do graphviz\n",
    "from graphviz import Digraph\n",
    "\n",
    "# Criar um objeto Digraph (para grafos direcionados)\n",
    "dot = graphviz.Digraph(comment='O Meu Grafo')\n",
    "\n",
    "# Adicionar nós\n",
    "dot.node('A', 'Nó A')\n",
    "dot.node('B', 'Nó B')\n",
    "dot.node('C', 'Nó C')\n",
    "\n",
    "# Adicionar arestas\n",
    "dot.edges(['AB', 'BC', 'CA'])\n",
    "\n",
    "# Salvar o gráfico como um arquivo DOT (opcional)\n",
    "dot.save('meu_grafo.dot')\n",
    "\n",
    "# Gerar uma visualização em PDF\n",
    "dot.render('meu_grafo', format='pdf', cleanup=True)\n",
    "\n",
    "# Gerar uma visualização em outros formatos, como PNG (opcional)\n",
    "dot.render('meu_grafo', format='png', cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process graph saved as 'process_graph.png'\n"
     ]
    }
   ],
   "source": [
    "# código do Caio \n",
    "import pandas as pd\n",
    "import pm4py\n",
    "from graphviz import Digraph\n",
    "\n",
    "def import_csv(file_path):\n",
    "    # Carregar o log de eventos a partir do arquivo CSV\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Converter a coluna 'timestamp' para o formato de data/hora\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "    \n",
    "    # Calcular o tempo gasto em cada ação para todos os pacientes\n",
    "    action_times = {}\n",
    "    for action in event_log['activity'].unique():\n",
    "        action_group = event_log[event_log['activity'] == action]\n",
    "        action_times[action] = action_group['timestamp'].max() - action_group['timestamp'].min()\n",
    "    \n",
    "    # Calcular a média dos tempos em segundos\n",
    "    total_time_seconds = sum(action_times.values(), pd.Timedelta(0)).total_seconds()\n",
    "    num_actions = len(action_times)\n",
    "    if num_actions != 0:\n",
    "        average_time_seconds = total_time_seconds / num_actions\n",
    "    else:\n",
    "        average_time_seconds = 0\n",
    "    \n",
    "    # Converter a média de volta para um objeto Timedelta\n",
    "    average_time = pd.Timedelta(seconds=average_time_seconds)\n",
    "    \n",
    "    # Descobrir o modelo de processo usando o algoritmo Alpha Miner\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    net, initial_marking, final_marking = pm4py.discover_petri_net_alpha(event_log)\n",
    "    \n",
    "    # Criar um objeto Digraph do Graphviz\n",
    "    dot = Digraph(comment='Process Mining', format='png')\n",
    "    \n",
    "    # Adicionar nós ao grafo\n",
    "    for p in net.places:\n",
    "        if p.name in action_times:\n",
    "            # Adicionar tempo médio como rótulo do nó\n",
    "            label = f\"{p.name} (Tempo médio: {action_times[p.name]})\"\n",
    "        else:\n",
    "            label = p.name\n",
    "        dot.node(p.name, label=label)\n",
    "    \n",
    "    # Adicionar transições ao grafo\n",
    "    for t in net.transitions:\n",
    "        dot.node(t.name, shape='rectangle', style='filled', fillcolor='lightblue')\n",
    "    \n",
    "    # Adicionar arestas ao grafo\n",
    "    for arc in net.arcs:\n",
    "        dot.edge(arc.source.name, arc.target.name)\n",
    "    \n",
    "    # Salvar o gráfico em um arquivo\n",
    "    dot.render('process_graph', format='png', cleanup=True)\n",
    "    print(\"Process graph saved as 'process_graph.png'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"C:\\\\Users\\\\betsabenogueira\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\"\n",
    "    import_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
