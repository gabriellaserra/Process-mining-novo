{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meu_grafo.png'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de como usar  graphviz\n",
    "import pandas as pd\n",
    "from graphviz import Digraph\n",
    "\n",
    "# Criar um novo grafo direcionado\n",
    "grafo = Digraph()\n",
    "\n",
    "# Adicionar nós e arestas ao grafo\n",
    "grafo.node('A')\n",
    "grafo.node('B')\n",
    "grafo.edge('A', 'B')\n",
    "\n",
    "# Visualizar o grafo\n",
    "grafo.render('meu_grafo', format='png', cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events:     case_id            activity                  timestamp  costs resource\n",
      "0         3    register request  2010-12-30 14:32:00+01:00     50     Pete\n",
      "1         3    examine casually  2010-12-30 15:06:00+01:00    400     Mike\n",
      "2         3        check ticket  2010-12-30 16:34:00+01:00    100    Ellen\n",
      "3         3              decide  2011-01-06 09:18:00+01:00    200     Sara\n",
      "4         3  reinitiate request  2011-01-06 12:18:00+01:00    200     Sara\n",
      "5         3  examine thoroughly  2011-01-06 13:06:00+01:00    400     Sean\n",
      "6         3        check ticket  2011-01-08 11:43:00+01:00    100     Pete\n",
      "7         3              decide  2011-01-09 09:55:00+01:00    200     Sara\n",
      "8         3    pay compensation  2011-01-15 10:45:00+01:00    200    Ellen\n",
      "9         2    register request  2010-12-30 11:32:00+01:00     50     Mike\n",
      "10        2        check ticket  2010-12-30 12:12:00+01:00    100     Mike\n",
      "11        2    examine casually  2010-12-30 14:16:00+01:00    400     Sean\n",
      "12        2              decide  2011-01-05 11:22:00+01:00    200     Sara\n",
      "13        2    pay compensation  2011-01-08 12:05:00+01:00    200    Ellen\n",
      "14        1    register request  2010-12-30 11:02:00+01:00     50     Pete\n",
      "15        1  examine thoroughly  2010-12-31 10:06:00+01:00    400      Sue\n",
      "16        1        check ticket  2011-01-05 15:12:00+01:00    100     Mike\n",
      "17        1              decide  2011-01-06 11:18:00+01:00    200     Sara\n",
      "18        1      reject request  2011-01-07 14:24:00+01:00    200     Pete\n",
      "19        6    register request  2011-01-06 15:02:00+01:00     50     Mike\n",
      "20        6    examine casually  2011-01-06 16:06:00+01:00    400    Ellen\n",
      "21        6        check ticket  2011-01-07 16:22:00+01:00    100     Mike\n",
      "22        6              decide  2011-01-07 16:52:00+01:00    200     Sara\n",
      "23        6    pay compensation  2011-01-16 11:47:00+01:00    200     Mike\n",
      "24        5    register request  2011-01-06 09:02:00+01:00     50    Ellen\n",
      "25        5    examine casually  2011-01-07 10:16:00+01:00    400     Mike\n",
      "26        5        check ticket  2011-01-08 11:22:00+01:00    100     Pete\n",
      "27        5              decide  2011-01-10 13:28:00+01:00    200     Sara\n",
      "28        5  reinitiate request  2011-01-11 16:18:00+01:00    200     Sara\n",
      "29        5        check ticket  2011-01-14 14:33:00+01:00    100    Ellen\n",
      "30        5    examine casually  2011-01-16 15:50:00+01:00    400     Mike\n",
      "31        5              decide  2011-01-19 11:18:00+01:00    200     Sara\n",
      "32        5  reinitiate request  2011-01-20 12:48:00+01:00    200     Sara\n",
      "33        5    examine casually  2011-01-21 09:06:00+01:00    400      Sue\n",
      "34        5        check ticket  2011-01-21 11:34:00+01:00    100     Pete\n",
      "35        5              decide  2011-01-23 13:12:00+01:00    200     Sara\n",
      "36        5      reject request  2011-01-24 14:56:00+01:00    200     Mike\n",
      "37        4    register request  2011-01-06 15:02:00+01:00     50     Pete\n",
      "38        4        check ticket  2011-01-07 12:06:00+01:00    100     Mike\n",
      "39        4  examine thoroughly  2011-01-08 14:43:00+01:00    400     Sean\n",
      "40        4              decide  2011-01-09 12:02:00+01:00    200     Sara\n",
      "41        4      reject request  2011-01-12 15:44:00+01:00    200    Ellen\n",
      "Number of cases: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "#Função para organizar e importar o arquivo\n",
    "def import_csv(file_path):\n",
    "    #o pandas tem várias funções para ler diferentes tipos de arquivos\n",
    "    event_log = pandas.read_csv(file_path, sep=';') #PARAMETROS: arquivo; 'sep' define que tipo de separação o arquivo tem, geralmente tem ',' como default\n",
    "    #event_log agora é uma 'tabela'\n",
    "    num_events = event_log\n",
    "    #.unique() retorna uma lista do id dos quantos clientes\n",
    "    num_cases = len(event_log.case_id.unique())\n",
    "    print(\"Number of events: {}\\nNumber of cases: {}\".format(num_events, num_cases))\n",
    "\n",
    "#forma de organizar o codigo: é uma prática padrão em Python para diferenciar a execução direta de um script da sua importação como um módulo.\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"C:\\\\Users\\\\meduarda\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linha Temporal: ['2010-12-30 11:02:00+01:00', '2010-12-30 11:32:00+01:00', '2010-12-30 12:12:00+01:00', '2010-12-30 14:16:00+01:00', '2010-12-30 14:32:00+01:00', '2010-12-30 15:06:00+01:00', '2010-12-30 16:34:00+01:00', '2010-12-31 10:06:00+01:00', '2011-01-05 11:22:00+01:00', '2011-01-05 15:12:00+01:00', '2011-01-06 09:02:00+01:00', '2011-01-06 09:18:00+01:00', '2011-01-06 11:18:00+01:00', '2011-01-06 12:18:00+01:00', '2011-01-06 13:06:00+01:00', '2011-01-06 15:02:00+01:00', '2011-01-06 15:02:00+01:00', '2011-01-06 16:06:00+01:00', '2011-01-07 10:16:00+01:00', '2011-01-07 12:06:00+01:00', '2011-01-07 14:24:00+01:00', '2011-01-07 16:22:00+01:00', '2011-01-07 16:52:00+01:00', '2011-01-08 11:22:00+01:00', '2011-01-08 11:43:00+01:00', '2011-01-08 12:05:00+01:00', '2011-01-08 14:43:00+01:00', '2011-01-09 09:55:00+01:00', '2011-01-09 12:02:00+01:00', '2011-01-10 13:28:00+01:00', '2011-01-11 16:18:00+01:00', '2011-01-12 15:44:00+01:00', '2011-01-14 14:33:00+01:00', '2011-01-15 10:45:00+01:00', '2011-01-16 11:47:00+01:00', '2011-01-16 15:50:00+01:00', '2011-01-19 11:18:00+01:00', '2011-01-20 12:48:00+01:00', '2011-01-21 09:06:00+01:00', '2011-01-21 11:34:00+01:00', '2011-01-23 13:12:00+01:00', '2011-01-24 14:56:00+01:00']\n",
      "Lista de eventos organizado: [(3, '2010-12-30 11:02:00+01:00'), (3, '2010-12-30 11:32:00+01:00'), (3, '2010-12-30 12:12:00+01:00'), (3, '2010-12-30 14:16:00+01:00'), (3, '2010-12-30 14:32:00+01:00'), (3, '2010-12-30 15:06:00+01:00'), (3, '2010-12-30 16:34:00+01:00'), (3, '2010-12-31 10:06:00+01:00'), (3, '2011-01-05 11:22:00+01:00'), (2, '2011-01-05 15:12:00+01:00'), (2, '2011-01-06 09:02:00+01:00'), (2, '2011-01-06 09:18:00+01:00'), (2, '2011-01-06 11:18:00+01:00'), (2, '2011-01-06 12:18:00+01:00'), (1, '2011-01-06 13:06:00+01:00'), (1, '2011-01-06 15:02:00+01:00'), (1, '2011-01-06 15:02:00+01:00'), (1, '2011-01-06 16:06:00+01:00'), (1, '2011-01-07 10:16:00+01:00'), (6, '2011-01-07 12:06:00+01:00'), (6, '2011-01-07 14:24:00+01:00'), (6, '2011-01-07 16:22:00+01:00'), (6, '2011-01-07 16:52:00+01:00'), (6, '2011-01-08 11:22:00+01:00'), (5, '2011-01-08 11:43:00+01:00'), (5, '2011-01-08 12:05:00+01:00'), (5, '2011-01-08 14:43:00+01:00'), (5, '2011-01-09 09:55:00+01:00'), (5, '2011-01-09 12:02:00+01:00'), (5, '2011-01-10 13:28:00+01:00'), (5, '2011-01-11 16:18:00+01:00'), (5, '2011-01-12 15:44:00+01:00'), (5, '2011-01-14 14:33:00+01:00'), (5, '2011-01-15 10:45:00+01:00'), (5, '2011-01-16 11:47:00+01:00'), (5, '2011-01-16 15:50:00+01:00'), (5, '2011-01-19 11:18:00+01:00'), (4, '2011-01-20 12:48:00+01:00'), (4, '2011-01-21 09:06:00+01:00'), (4, '2011-01-21 11:34:00+01:00'), (4, '2011-01-23 13:12:00+01:00'), (4, '2011-01-24 14:56:00+01:00')]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pandas.read_csv(file_path, sep=';')\n",
    "    num_cases = event_log.case_id\n",
    "    #organiza a lista em ordem de eventos pelo tempo\n",
    "    clients = sorted(event_log.timestamp)\n",
    "    listaOrganizada = list(zip(num_cases, clients))\n",
    "    print(\"Linha Temporal: {}\\nLista de eventos organizado: {}\".format(clients, listaOrganizada))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"C:\\\\Users\\\\meduarda\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "case_id column (case ID) is not in the dataframe!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     grafo\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeugrafico\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m, cleanup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mimport_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mmeduarda\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mgrupo-2\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mBases_de_Dados\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mrunning-example.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[54], line 7\u001b[0m, in \u001b[0;36mimport_csv\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_csv\u001b[39m(file_path):\n\u001b[0;32m      6\u001b[0m     event_log \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mread_csv(file_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     activity \u001b[38;5;241m=\u001b[39m \u001b[43mpm4py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_log\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcase_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivity_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     num_cases \u001b[38;5;241m=\u001b[39m event_log\u001b[38;5;241m.\u001b[39mcase_id\n\u001b[0;32m      9\u001b[0m     grafo \u001b[38;5;241m=\u001b[39m Digraph()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pm4py\\utils.py:69\u001b[0m, in \u001b[0;36mformat_dataframe\u001b[1;34m(df, case_id, activity_key, timestamp_key, start_timestamp_key, timest_format)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpm4py\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataframe_utils\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m case_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(case_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m column (case ID) is not in the dataframe!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m activity_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(activity_key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m column (activity) is not in the dataframe!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: case_id column (case ID) is not in the dataframe!"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import graphviz as grafo\n",
    "import pm4py\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pandas.read_csv(file_path, sep=';')\n",
    "    activity = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    num_cases = event_log.case_id\n",
    "    grafo = Digraph()\n",
    "    for case_id in num_cases.unique():\n",
    "        grafo.node(str(case_id))\n",
    "    for i in range(len(event_log)-1): #Passa por todas a linhas da tabela\n",
    "        grafo.edge(str(event_log.loc[i, 'case_id']), str(event_log.loc[i+1, 'case_id'])) #Pega uma linha da coluna 'case_id' e referencia com a próxima linha\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    grafo.render('meugrafico', format='png', cleanup=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"C:\\\\Users\\\\meduarda\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.csv\")\n",
    "\n",
    "#ta dando erro (>~<)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
