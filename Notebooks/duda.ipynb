{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meu_grafo.png'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de como usar  graphviz\n",
    "import pandas as pd\n",
    "from graphviz import Digraph\n",
    "\n",
    "# Criar um novo grafo direcionado\n",
    "grafo = Digraph()\n",
    "\n",
    "# Adicionar nós e arestas ao grafo\n",
    "grafo.node('A')\n",
    "grafo.node('B')\n",
    "grafo.edge('A', 'B')\n",
    "\n",
    "# Visualizar o grafo\n",
    "grafo.render('meu_grafo', format='png', cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events:     case_id            activity                  timestamp  costs resource\n",
      "0         3    register request  2010-12-30 14:32:00+01:00     50     Pete\n",
      "1         3    examine casually  2010-12-30 15:06:00+01:00    400     Mike\n",
      "2         3        check ticket  2010-12-30 16:34:00+01:00    100    Ellen\n",
      "3         3              decide  2011-01-06 09:18:00+01:00    200     Sara\n",
      "4         3  reinitiate request  2011-01-06 12:18:00+01:00    200     Sara\n",
      "5         3  examine thoroughly  2011-01-06 13:06:00+01:00    400     Sean\n",
      "6         3        check ticket  2011-01-08 11:43:00+01:00    100     Pete\n",
      "7         3              decide  2011-01-09 09:55:00+01:00    200     Sara\n",
      "8         3    pay compensation  2011-01-15 10:45:00+01:00    200    Ellen\n",
      "9         2    register request  2010-12-30 11:32:00+01:00     50     Mike\n",
      "10        2        check ticket  2010-12-30 12:12:00+01:00    100     Mike\n",
      "11        2    examine casually  2010-12-30 14:16:00+01:00    400     Sean\n",
      "12        2              decide  2011-01-05 11:22:00+01:00    200     Sara\n",
      "13        2    pay compensation  2011-01-08 12:05:00+01:00    200    Ellen\n",
      "14        1    register request  2010-12-30 11:02:00+01:00     50     Pete\n",
      "15        1  examine thoroughly  2010-12-31 10:06:00+01:00    400      Sue\n",
      "16        1        check ticket  2011-01-05 15:12:00+01:00    100     Mike\n",
      "17        1              decide  2011-01-06 11:18:00+01:00    200     Sara\n",
      "18        1      reject request  2011-01-07 14:24:00+01:00    200     Pete\n",
      "19        6    register request  2011-01-06 15:02:00+01:00     50     Mike\n",
      "20        6    examine casually  2011-01-06 16:06:00+01:00    400    Ellen\n",
      "21        6        check ticket  2011-01-07 16:22:00+01:00    100     Mike\n",
      "22        6              decide  2011-01-07 16:52:00+01:00    200     Sara\n",
      "23        6    pay compensation  2011-01-16 11:47:00+01:00    200     Mike\n",
      "24        5    register request  2011-01-06 09:02:00+01:00     50    Ellen\n",
      "25        5    examine casually  2011-01-07 10:16:00+01:00    400     Mike\n",
      "26        5        check ticket  2011-01-08 11:22:00+01:00    100     Pete\n",
      "27        5              decide  2011-01-10 13:28:00+01:00    200     Sara\n",
      "28        5  reinitiate request  2011-01-11 16:18:00+01:00    200     Sara\n",
      "29        5        check ticket  2011-01-14 14:33:00+01:00    100    Ellen\n",
      "30        5    examine casually  2011-01-16 15:50:00+01:00    400     Mike\n",
      "31        5              decide  2011-01-19 11:18:00+01:00    200     Sara\n",
      "32        5  reinitiate request  2011-01-20 12:48:00+01:00    200     Sara\n",
      "33        5    examine casually  2011-01-21 09:06:00+01:00    400      Sue\n",
      "34        5        check ticket  2011-01-21 11:34:00+01:00    100     Pete\n",
      "35        5              decide  2011-01-23 13:12:00+01:00    200     Sara\n",
      "36        5      reject request  2011-01-24 14:56:00+01:00    200     Mike\n",
      "37        4    register request  2011-01-06 15:02:00+01:00     50     Pete\n",
      "38        4        check ticket  2011-01-07 12:06:00+01:00    100     Mike\n",
      "39        4  examine thoroughly  2011-01-08 14:43:00+01:00    400     Sean\n",
      "40        4              decide  2011-01-09 12:02:00+01:00    200     Sara\n",
      "41        4      reject request  2011-01-12 15:44:00+01:00    200    Ellen\n",
      "Number of cases: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "#Função para organizar e importar o arquivo\n",
    "def import_csv(file_path):\n",
    "    #o pandas tem várias funções para ler diferentes tipos de arquivos\n",
    "    event_log = pandas.read_csv(file_path, sep=';') #PARAMETROS: arquivo; 'sep' define que tipo de separação o arquivo tem, geralmente tem ',' como default\n",
    "    #event_log agora é uma 'tabela'\n",
    "    num_events = event_log\n",
    "    #.unique() retorna uma lista do id dos quantos clientes\n",
    "    num_cases = len(event_log.case_id.unique())\n",
    "    print(\"Number of events: {}\\nNumber of cases: {}\".format(num_events, num_cases))\n",
    "\n",
    "#forma de organizar o codigo: é uma prática padrão em Python para diferenciar a execução direta de um script da sua importação como um módulo.\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"C:\\\\Users\\\\meduarda\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linha Temporal: ['2010-12-30 11:02:00+01:00', '2010-12-30 11:32:00+01:00', '2010-12-30 12:12:00+01:00', '2010-12-30 14:16:00+01:00', '2010-12-30 14:32:00+01:00', '2010-12-30 15:06:00+01:00', '2010-12-30 16:34:00+01:00', '2010-12-31 10:06:00+01:00', '2011-01-05 11:22:00+01:00', '2011-01-05 15:12:00+01:00', '2011-01-06 09:02:00+01:00', '2011-01-06 09:18:00+01:00', '2011-01-06 11:18:00+01:00', '2011-01-06 12:18:00+01:00', '2011-01-06 13:06:00+01:00', '2011-01-06 15:02:00+01:00', '2011-01-06 15:02:00+01:00', '2011-01-06 16:06:00+01:00', '2011-01-07 10:16:00+01:00', '2011-01-07 12:06:00+01:00', '2011-01-07 14:24:00+01:00', '2011-01-07 16:22:00+01:00', '2011-01-07 16:52:00+01:00', '2011-01-08 11:22:00+01:00', '2011-01-08 11:43:00+01:00', '2011-01-08 12:05:00+01:00', '2011-01-08 14:43:00+01:00', '2011-01-09 09:55:00+01:00', '2011-01-09 12:02:00+01:00', '2011-01-10 13:28:00+01:00', '2011-01-11 16:18:00+01:00', '2011-01-12 15:44:00+01:00', '2011-01-14 14:33:00+01:00', '2011-01-15 10:45:00+01:00', '2011-01-16 11:47:00+01:00', '2011-01-16 15:50:00+01:00', '2011-01-19 11:18:00+01:00', '2011-01-20 12:48:00+01:00', '2011-01-21 09:06:00+01:00', '2011-01-21 11:34:00+01:00', '2011-01-23 13:12:00+01:00', '2011-01-24 14:56:00+01:00']\n",
      "Lista de eventos organizado: [(3, '2010-12-30 11:02:00+01:00'), (3, '2010-12-30 11:32:00+01:00'), (3, '2010-12-30 12:12:00+01:00'), (3, '2010-12-30 14:16:00+01:00'), (3, '2010-12-30 14:32:00+01:00'), (3, '2010-12-30 15:06:00+01:00'), (3, '2010-12-30 16:34:00+01:00'), (3, '2010-12-31 10:06:00+01:00'), (3, '2011-01-05 11:22:00+01:00'), (2, '2011-01-05 15:12:00+01:00'), (2, '2011-01-06 09:02:00+01:00'), (2, '2011-01-06 09:18:00+01:00'), (2, '2011-01-06 11:18:00+01:00'), (2, '2011-01-06 12:18:00+01:00'), (1, '2011-01-06 13:06:00+01:00'), (1, '2011-01-06 15:02:00+01:00'), (1, '2011-01-06 15:02:00+01:00'), (1, '2011-01-06 16:06:00+01:00'), (1, '2011-01-07 10:16:00+01:00'), (6, '2011-01-07 12:06:00+01:00'), (6, '2011-01-07 14:24:00+01:00'), (6, '2011-01-07 16:22:00+01:00'), (6, '2011-01-07 16:52:00+01:00'), (6, '2011-01-08 11:22:00+01:00'), (5, '2011-01-08 11:43:00+01:00'), (5, '2011-01-08 12:05:00+01:00'), (5, '2011-01-08 14:43:00+01:00'), (5, '2011-01-09 09:55:00+01:00'), (5, '2011-01-09 12:02:00+01:00'), (5, '2011-01-10 13:28:00+01:00'), (5, '2011-01-11 16:18:00+01:00'), (5, '2011-01-12 15:44:00+01:00'), (5, '2011-01-14 14:33:00+01:00'), (5, '2011-01-15 10:45:00+01:00'), (5, '2011-01-16 11:47:00+01:00'), (5, '2011-01-16 15:50:00+01:00'), (5, '2011-01-19 11:18:00+01:00'), (4, '2011-01-20 12:48:00+01:00'), (4, '2011-01-21 09:06:00+01:00'), (4, '2011-01-21 11:34:00+01:00'), (4, '2011-01-23 13:12:00+01:00'), (4, '2011-01-24 14:56:00+01:00')]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pandas.read_csv(file_path, sep=';')\n",
    "    num_cases = event_log.case_id\n",
    "    #organiza a lista em ordem de eventos pelo tempo\n",
    "    clients = sorted(event_log.timestamp)\n",
    "    listaOrganizada = list(zip(num_cases, clients))\n",
    "    print(\"Linha Temporal: {}\\nLista de eventos organizado: {}\".format(clients, listaOrganizada))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"C:\\\\Users\\\\meduarda\\\\grupo-2\\\\Bases_de_Dados\\\\running-example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import graphviz as gv\n",
    "from graphviz import Digraph\n",
    "from datetime import datetime\n",
    "import pm4py\n",
    "import os\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "\n",
    "    grafo = Digraph()\n",
    "    \n",
    "    # Criação de nós com IDs únicos e labels de timestamp\n",
    "    for i, row in event_log.iterrows():\n",
    "        timestamp_str = row['timestamp'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "        grafo.node(str(i), label=timestamp_str)\n",
    "    \n",
    "    # Criação de arestas entre eventos sequenciais\n",
    "    for i in range(len(event_log) - 1):\n",
    "        grafo.edge(str(i), str(i + 1))\n",
    "\n",
    "    # grafo.render('meu_grafo', format='png', cleanup=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"C:\\\\Users\\\\meduarda\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\")\n",
    "\n",
    "# não é uma rede de petri, eu estou aprendendo a usar o graphviz ainda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process graph saved as 'process_graph.png'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "from graphviz import Digraph\n",
    "\n",
    "def import_csv(file_path):\n",
    "    # Carregar o log de eventos a partir do arquivo CSV\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Converter a coluna 'timestamp' para o formato de data/hora\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "    \n",
    "    # Calcular o tempo gasto em cada ação para todos os pacientes\n",
    "    action_times = {}\n",
    "    action_freq = {}\n",
    "    for action in event_log['activity'].unique():\n",
    "        action_group = event_log[event_log['activity'] == action]\n",
    "        action_times[action] = action_group['timestamp'].max() - action_group['timestamp'].min()\n",
    "        action_freq[action] = len(action_group['case_id'].unique())\n",
    "    \n",
    "    # Calcular a frequência e o tempo médio de cada situação\n",
    "    situation_freq = {}\n",
    "    situation_times = {}\n",
    "    for i, situation in event_log[['activity', 'case_id']].drop_duplicates().iterrows():\n",
    "        situation_group = event_log[(event_log['activity'] == situation['activity']) & (event_log['case_id'] == situation['case_id'])]\n",
    "        situation_freq[situation['activity']] = len(situation_group['case_id'].unique())\n",
    "        situation_times[situation['activity']] = (situation_group['timestamp'].max() - situation_group['timestamp'].min()) / situation_freq[situation['activity']]\n",
    "    \n",
    "    # Calcular a média dos tempos em horas\n",
    "    total_time_hours = sum(action_times.values(), pd.Timedelta(0)).total_seconds() / 3600\n",
    "    num_actions = len(action_times)\n",
    "    if num_actions != 0:\n",
    "        average_time_hours = total_time_hours / num_actions\n",
    "    else:\n",
    "        average_time_hours = 0\n",
    "    \n",
    "    # Descobrir o modelo de processo usando o algoritmo Alpha Miner\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    net, initial_marking, final_marking = pm4py.discover_petri_net_alpha(event_log)\n",
    "    \n",
    "    # Criar um objeto Digraph do Graphviz\n",
    "    dot = Digraph(comment='Process Mining', format='png')\n",
    "    \n",
    "    # Adicionar nós ao grafo\n",
    "    for p in net.places:\n",
    "        if p.name in situation_times:\n",
    "            # Adicionar frequência e tempo médio como rótulo do nó\n",
    "            if situation_times[p.name] >= pd.Timedelta(days=1):\n",
    "                label = f\"{p.name} (Freq.: {situation_freq[p.name]}, Tempo médio: {situation_times[p.name].days:.1f} dias)\"\n",
    "            else:\n",
    "                label = f\"{p.name} (Freq.: {situation_freq[p.name]}, Tempo médio: {situation_times[p.name].seconds / 3600:.1f} horas)\"\n",
    "        else:\n",
    "            label = p.name\n",
    "        if p.name == \"start\":\n",
    "            dot.node(p.name, label=label, style=\"filled\", fillcolor=\"green\")\n",
    "        elif p.name == \"end\":\n",
    "            dot.node(p.name, label=label, style=\"filled\", fillcolor=\"green\")\n",
    "        else:\n",
    "            dot.node(p.name, label=label)\n",
    "\n",
    "    dot.edge(\"start\", list(net.transitions)[0].name, style=\"invis\")\n",
    "    dot.edge(list(net.transitions)[-1].name, \"end\", style=\"invis\")\n",
    "    \n",
    "    # Adicionar transições ao grafo\n",
    "    for t in net.transitions:\n",
    "        if t.name in action_times:\n",
    "            label = f\"{t.name}\\nFreq.: {action_freq[t.name]}\\nTempo médio: {action_times[t.name].seconds / 3600:.1f} horas\"\n",
    "        else:\n",
    "            label = t.name\n",
    "\n",
    "        dot.node(t.name, label=label, shape='rectangle', style='filled', fillcolor='lightblue')\n",
    "    \n",
    "    # Adicionar arestas ao grafo\n",
    "    for arc in net.arcs:\n",
    "        dot.edge(arc.source.name, arc.target.name)\n",
    "       \n",
    "\n",
    "    # Salvar o gráfico em um arquivo\n",
    "    dot.render('process_graph', format='png', cleanup=True)\n",
    "    print(\"Process graph saved as 'process_graph.png'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"C:\\\\Users\\\\meduarda\\\\grupo-2-2\\\\Bases_de_Dados\\\\running-example_3.csv\"\n",
    "    import_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['register request' 'examine casually' 'check ticket' 'decide'\n",
      " 'reinitiate request' 'examine thoroughly' 'pay compensation'\n",
      " 'reject request']\n",
      "Tempo médio total: 19 days 08:53:50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Converter a coluna 'timestamp' para o formato de data/hora\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "    \n",
    "    # Calcular o tempo gasto em cada ação para todos os pacientes\n",
    "    action_times = {}\n",
    "    for action in event_log.activity.unique():\n",
    "        action_group = event_log[event_log['activity'] == action]\n",
    "        action_times[action] = action_group['timestamp'].max() - action_group['timestamp'].min()\n",
    "    \n",
    "    # Calcular a média dos tempos em segundos\n",
    "    total_time_seconds = sum(action_times.values(), pd.Timedelta(0)).total_seconds()\n",
    "    num_patients = len(event_log['case_id'].unique())\n",
    "    average_time_seconds = total_time_seconds / num_patients\n",
    "    \n",
    "    # Converter a média de volta para um objeto Timedelta\n",
    "    average_time = pd.Timedelta(seconds=average_time_seconds)\n",
    "    \n",
    "    # Imprimir o resultado para todas as ações\n",
    "    for action, time in action_times.items():\n",
    "        total_seconds = time.total_seconds()\n",
    "        minutes, seconds = divmod(total_seconds, 60)\n",
    "        print(f\"Ação: {action} - Tempo médio: {minutes:.0f} minutos e {seconds:.0f} segundos\")\n",
    "        \n",
    "    \n",
    "    print(f\"Tempo médio total: {average_time}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"C:\\\\Users\\\\meduarda\\\\grupo-2-1\\\\Bases_de_Dados\\\\running-example_3.csv\" \n",
    "    import_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: (['register request', '2010-12-30 14:32:00+01:00'], ['examine casually', '2010-12-30 15:06:00+01:00'], ['check ticket', '2010-12-30 16:34:00+01:00'], ['decide', '2011-01-06 09:18:00+01:00'], ['reinitiate request', '2011-01-06 12:18:00+01:00'], ['examine thoroughly', '2011-01-06 13:06:00+01:00'], ['check ticket', '2011-01-08 11:43:00+01:00'], ['decide', '2011-01-09 09:55:00+01:00'], ['pay compensation', '2011-01-15 10:45:00+01:00']), 2: (['register request', '2010-12-30 11:32:00+01:00'], ['check ticket', '2010-12-30 12:12:00+01:00'], ['examine casually', '2010-12-30 14:16:00+01:00'], ['decide', '2011-01-05 11:22:00+01:00'], ['pay compensation', '2011-01-08 12:05:00+01:00']), 1: (['register request', '2010-12-30 11:02:00+01:00'], ['examine thoroughly', '2010-12-31 10:06:00+01:00'], ['check ticket', '2011-01-05 15:12:00+01:00'], ['decide', '2011-01-06 11:18:00+01:00'], ['reject request', '2011-01-07 14:24:00+01:00']), 6: (['register request', '2011-01-06 15:02:00+01:00'], ['examine casually', '2011-01-06 16:06:00+01:00'], ['check ticket', '2011-01-07 16:22:00+01:00'], ['decide', '2011-01-07 16:52:00+01:00'], ['pay compensation', '2011-01-16 11:47:00+01:00']), 5: (['register request', '2011-01-06 09:02:00+01:00'], ['examine casually', '2011-01-07 10:16:00+01:00'], ['check ticket', '2011-01-08 11:22:00+01:00'], ['decide', '2011-01-10 13:28:00+01:00'], ['reinitiate request', '2011-01-11 16:18:00+01:00'], ['check ticket', '2011-01-14 14:33:00+01:00'], ['examine casually', '2011-01-16 15:50:00+01:00'], ['decide', '2011-01-19 11:18:00+01:00'], ['reinitiate request', '2011-01-20 12:48:00+01:00'], ['examine casually', '2011-01-21 09:06:00+01:00'], ['check ticket', '2011-01-21 11:34:00+01:00'], ['decide', '2011-01-23 13:12:00+01:00'], ['reject request', '2011-01-24 14:56:00+01:00']), 4: (['register request', '2011-01-06 15:02:00+01:00'], ['check ticket', '2011-01-07 12:06:00+01:00'], ['examine thoroughly', '2011-01-08 14:43:00+01:00'], ['decide', '2011-01-09 12:02:00+01:00'], ['reject request', '2011-01-12 15:44:00+01:00'])}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "import os\n",
    "from graphviz import Digraph\n",
    "\n",
    "def import_csv(file_path):\n",
    "    # Carregar o log de eventos a partir do arquivo CSV\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    # Dicionário parra cada pessoa\n",
    "    dicPessoa = dict()\n",
    "    listaPessoas = list(event_log['case_id'])\n",
    "    listaProcessos = list(event_log['activity'])\n",
    "    listaPeriodos = list(event_log['timestamp'])\n",
    "    \n",
    "    dicPessoas = {}\n",
    "    for (i,pessoa) in enumerate(listaPessoas):\n",
    "        if pessoa in dicPessoas:\n",
    "            dicPessoas[pessoa] += tuple([[listaProcessos[i],listaPeriodos[i]]])\n",
    "        else:\n",
    "            dicPessoas[pessoa] = tuple([[listaProcessos[i],listaPeriodos[i]]])\n",
    "    print(dicPessoas)\n",
    "\n",
    "    # print(listaAtividades)\n",
    "    # print(listaCasos)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"C:\\\\Users\\\\meduarda\\\\grupo-2-2\\\\Bases_de_Dados\\\\running-example_3.csv\"\n",
    "    import_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from datetime import datetime as dt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log = pandas.read_csv('C:\\\\Users\\\\meduarda\\\\grupo-2-2\\\\Bases_de_Dados\\\\running-example_3.csv', sep = ';')\n",
    "\n",
    "    listaAtividades = list(log.activity)\n",
    "    listaCasos = list(log.case_id)\n",
    "    listaHoras = list(log.timestamp)\n",
    "\n",
    "    for (i, hora) in enumerate(listaHoras):\n",
    "        hora = dt.strptime(hora,\"%Y-%m-%d %H:%M:%S%z\")\n",
    "        listaHoras[i] = hora.replace(tzinfo=None)\n",
    "\n",
    "    dicPessoas = {}\n",
    "    for (i,pessoa) in enumerate(listaCasos):\n",
    "        if pessoa in dicPessoas:\n",
    "            dicPessoas[pessoa] += tuple([[listaAtividades[i],listaHoras[i]]])\n",
    "        else:\n",
    "            dicPessoas[pessoa] = tuple([[listaAtividades[i],listaHoras[i]]])\n",
    "\n",
    "    \n",
    "    dicIntervalos = {}\n",
    "\n",
    "    for key in dicPessoas:\n",
    "        listaVazia = []\n",
    "        for atividades in dicPessoas[key]:\n",
    "            listaVazia.append(atividades)\n",
    "        for (i,el) in enumerate(listaVazia):\n",
    "            if el[0] not in dicIntervalos:\n",
    "                if i == (len(listaVazia)-1):\n",
    "                    dicIntervalos[el[0]] == 0\n",
    "                else:\n",
    "                    dicIntervalos[el[0]] = listaVazia[i+1][1] - el[1]\n",
    "            else:\n",
    "                dicIntervalos[el[0]] += listaVazia[i+1][1] - el[1]\n",
    "\n",
    "    print(dicIntervalos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNÇÕES INTERESSANTES:\n",
    "### pm4py\n",
    "### pandas\n",
    "### graphviz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando imagens com o arquivo padrão do pm4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start activities: {'register request': 6}\n",
      "End activities: {'reject request': 3, 'pay compensation': 3}\n",
      "Number of events: 42\n",
      "Number of cases: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pandas.read_csv(file_path, sep=';')\n",
    "    num_events = len(event_log)\n",
    "    num_cases = len(event_log.case_id.unique())\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    start_activities = pm4py.get_start_activities(event_log)\n",
    "    end_activities = pm4py.get_end_activities(event_log)\n",
    "    print(\"Start activities: {}\\nEnd activities: {}\".format(start_activities, end_activities))\n",
    "    print(\"Number of events: {}\\nNumber of cases: {}\".format(num_events, num_cases))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"C:\\\\Users\\\\meduarda\\\\grupo-2-3\\\\Bases_de_Dados\\\\running-example_3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
