{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arq=open(\"Y:\\\\git\\\\Process Mining\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\", \"r\")\n",
    "for linha in arq:\n",
    "    linha=linha.strip().split(\";\")\n",
    "    print (linha)\n",
    "arq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pm4py\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pandas.read_csv(file_path, sep=';') #Carrega o log de eventos\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp') #Cria uma cópia do log e renomeia as colunas para o padrão usado no pm4py\n",
    "    start_activities = pm4py.get_start_activities(event_log) #Número de rastreamento que ocorrem primeiro\n",
    "    end_activities = pm4py.get_end_activities(event_log) #Número de rastreamentos que ocorrem no final\n",
    "    num_events = len(event_log) #Numero de eventos\n",
    "    num_cases = len(event_log.case_id.unique()) #Numero de casos\n",
    "    print(\"Número de eventos: {}\\nNúmero de casos: {}\".format(num_events, num_cases)) #Exibir o número de eventos e de casos\n",
    "    print(\"Inicio das Atividades: {}\\nFim das Atividades: {}\".format(start_activities, end_activities)) #Exibir o inicio e o fim das atividades\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_csv(\"Y:\\\\git\\\\Process Mining\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paciente 1: Tempo total no hospital: 8 days 03:22:00\n",
      "Paciente 2: Tempo total no hospital: 9 days 00:33:00\n",
      "Paciente 3: Tempo total no hospital: 15 days 20:13:00\n",
      "Paciente 4: Tempo total no hospital: 6 days 00:42:00\n",
      "Paciente 5: Tempo total no hospital: 18 days 05:54:00\n",
      "Paciente 6: Tempo total no hospital: 9 days 20:45:00\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> ac88677e494437817b6bd82380097ee90bb2b0e8
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Converter a coluna 'timestamp' para o formato de data/hora\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "    \n",
    "    # Agrupar os eventos por paciente\n",
    "    grouped_events = event_log.groupby('case_id')\n",
    "    \n",
    "    # Calcular o tempo total para cada paciente\n",
    "    for case_id, group in grouped_events:\n",
    "        first_event_time = group['timestamp'].min()\n",
    "        last_event_time = group['timestamp'].max()\n",
    "        total_time = last_event_time - first_event_time\n",
    "        \n",
    "        # Imprimir o resultado\n",
    "        print(f\"Paciente {case_id}: Tempo total no hospital: {total_time}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"Y:\\\\git\\\\Process Mining\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\"  \n",
    "    import_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ação: register request - Tempo médio: 10320 minutos e 0 segundos\n",
      "Ação: examine casually - Tempo médio: 31370 minutos e 0 segundos\n",
      "Ação: check ticket - Tempo médio: 31642 minutos e 0 segundos\n",
      "Ação: decide - Tempo médio: 26030 minutos e 0 segundos\n",
      "Ação: reinitiate request - Tempo médio: 20190 minutos e 0 segundos\n",
      "Ação: examine thoroughly - Tempo médio: 11797 minutos e 0 segundos\n",
      "Ação: pay compensation - Tempo médio: 11502 minutos e 0 segundos\n",
      "Ação: reject request - Tempo médio: 24512 minutos e 0 segundos\n",
      "Tempo médio total: 19 days 08:53:50\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> ac88677e494437817b6bd82380097ee90bb2b0e8
   "source": [
    "import pandas as pd\n",
    "\n",
    "def import_csv(file_path):\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Converter a coluna 'timestamp' para o formato de data/hora\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "    \n",
    "    # Calcular o tempo gasto em cada ação para todos os pacientes\n",
    "    action_times = {}\n",
    "    for action in event_log['activity'].unique():\n",
    "        action_group = event_log[event_log['activity'] == action]\n",
    "        action_times[action] = action_group['timestamp'].max() - action_group['timestamp'].min()\n",
    "    \n",
    "    # Calcular a média dos tempos em segundos\n",
    "    total_time_seconds = sum(action_times.values(), pd.Timedelta(0)).total_seconds()\n",
    "    num_patients = len(event_log['case_id'].unique())\n",
    "    average_time_seconds = total_time_seconds / num_patients\n",
    "    \n",
    "    # Converter a média de volta para um objeto Timedelta\n",
    "    average_time = pd.Timedelta(seconds=average_time_seconds)\n",
    "    \n",
    "    # Imprimir o resultado para todas as ações\n",
    "    for action, time in action_times.items():\n",
    "        total_seconds = time.total_seconds()\n",
    "        minutes, seconds = divmod(total_seconds, 60)\n",
<<<<<<< HEAD
    "        print(f\"Ação: {action} - Tempo médio: {minutes:.0f} minutos e {seconds:.0f} segundos\")\n",
=======
    "        hours, minutes = divmod(minutes,60)\n",
    "        \n",
    "        print(f\"Ação: {action} - Tempo médio: {hours:.0f} horas {minutes:.0f} minutos e {seconds:.0f} segundos\")\n",
>>>>>>> ac88677e494437817b6bd82380097ee90bb2b0e8
    "    \n",
    "    print(f\"Tempo médio total: {average_time}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"Y:\\\\git\\\\Process Mining\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\" \n",
<<<<<<< HEAD
=======
    "    import_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "import graphviz\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "import os\n",
    "\n",
    "def import_csv(file_path):\n",
    "    # Carregar o log de eventos a partir do arquivo CSV\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Converter a coluna 'timestamp' para o formato de data/hora\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "    \n",
    "    # Calcular o tempo gasto em cada ação para todos os pacientes\n",
    "    action_times = {}\n",
    "    for action in event_log['activity'].unique():\n",
    "        action_group = event_log[event_log['activity'] == action]\n",
    "        action_times[action] = action_group['timestamp'].max() - action_group['timestamp'].min()\n",
    "    \n",
    "    # Calcular a média dos tempos em segundos\n",
    "    total_time_seconds = sum(action_times.values(), pd.Timedelta(0)).total_seconds()\n",
    "    num_patients = len(event_log['case_id'].unique())\n",
    "    average_time_seconds = total_time_seconds / num_patients\n",
    "    \n",
    "    # Converter a média de volta para um objeto Timedelta\n",
    "    average_time = pd.Timedelta(seconds=average_time_seconds)\n",
    "    \n",
    "    # Imprimir o resultado para todas as ações\n",
    "    for action, time in action_times.items():\n",
    "        total_seconds = time.total_seconds()\n",
    "        minutes, seconds = divmod(total_seconds, 60)\n",
    "        hours, minutes = divmod(minutes, 60)\n",
    "        \n",
    "        print(f\"Ação: {action} - Tempo médio: {hours:.0f} horas, {minutes:.0f} minutos e {seconds:.0f} segundos\")\n",
    "    \n",
    "    print(f\"Tempo médio total: {average_time}\")\n",
    "    \n",
    "    # Descobrir o modelo de processo usando o algoritmo Alpha Miner\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    net, initial_marking, final_marking = alpha_miner.apply(event_log)\n",
    "    \n",
    "    # Visualizar o modelo de processo\n",
    "    os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Program Files\\\\Graphviz\\\\bin'  # Adicione o diretório do Graphviz ao PATH\n",
    "    gviz = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "    pn_visualizer.view(gviz)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"Y:\\\\git\\\\Process Mining\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\"\n",
    "    import_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process graph saved as 'process_graph.png'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "import os\n",
    "from graphviz import Digraph\n",
    "\n",
    "def import_csv(file_path):\n",
    "    # Carregar o log de eventos a partir do arquivo CSV\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Converter a coluna 'timestamp' para o formato de data/hora\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "    \n",
    "    # Calcular o tempo gasto em cada ação para todos os pacientes\n",
    "    action_times = {}\n",
    "    for action in event_log['activity'].unique():\n",
    "        action_group = event_log[event_log['activity'] == action]\n",
    "        action_times[action] = action_group['timestamp'].max() - action_group['timestamp'].min()\n",
    "    \n",
    "    # Calcular a média dos tempos em segundos\n",
    "    total_time_seconds = sum(action_times.values(), pd.Timedelta(0)).total_seconds()\n",
    "    num_actions = len(action_times)\n",
    "    if num_actions != 0:\n",
    "        average_time_seconds = total_time_seconds / num_actions\n",
    "    else:\n",
    "        average_time_seconds = 0\n",
    "    \n",
    "    # Converter a média de volta para um objeto Timedelta\n",
    "    average_time = pd.Timedelta(seconds=average_time_seconds)\n",
    "    \n",
    "    # Descobrir o modelo de processo usando o algoritmo Alpha Miner\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    net, initial_marking, final_marking = pm4py.discover_petri_net_alpha(event_log)\n",
    "    \n",
    "    # Criar um objeto Digraph do Graphviz\n",
    "    dot = Digraph(comment='Process Mining', format='png')\n",
    "    \n",
    "    # Adicionar nós ao grafo\n",
    "    for p in net.places:\n",
    "        if p.name in action_times:\n",
    "            # Adicionar tempo médio como rótulo do nó\n",
    "            label = f\"{p.name} (Tempo médio: {action_times[p.name]})\"\n",
    "        else:\n",
    "            label = p.name\n",
    "        dot.node(p.name, label=label)\n",
    "    \n",
    "    # Adicionar transições ao grafo\n",
    "    for t in net.transitions:\n",
    "        dot.node(t.name, shape='rectangle', style='filled', fillcolor='lightblue')\n",
    "    \n",
    "    # Adicionar arestas ao grafo\n",
    "    for arc in net.arcs:\n",
    "        dot.edge(arc.source.name, arc.target.name)\n",
    "    \n",
    "    # Salvar o gráfico em um arquivo\n",
    "    dot.render('process_graph', format='png', cleanup=True)\n",
    "    print(\"Process graph saved as 'process_graph.png'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"Y:\\\\git\\\\Process Mining\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\"\n",
>>>>>>> ac88677e494437817b6bd82380097ee90bb2b0e8
    "    import_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process graph saved as 'process_graph.png'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "from graphviz import Digraph\n",
    "import random  # Adicionando import para a função random\n",
    "\n",
    "def import_csv(file_path):\n",
    "    # Carregar o log de eventos a partir do arquivo CSV\n",
    "    event_log = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Converter a coluna 'timestamp' para o formato de data/hora\n",
    "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "    \n",
    "    # Calcular o tempo gasto em cada ação para todos os pacientes\n",
    "    action_times = {}\n",
    "    action_freq = {}\n",
    "    for action in event_log['activity'].unique():\n",
    "        action_group = event_log[event_log['activity'] == action]\n",
    "        action_times[action] = action_group['timestamp'].max() - action_group['timestamp'].min()\n",
    "        action_freq[action] = len(action_group['case_id'].unique())\n",
    "    \n",
    "    # Calcular a frequência e o tempo médio de cada situação\n",
    "    situation_freq = {}\n",
    "    situation_times = {}\n",
    "    for i, situation in event_log[['activity', 'case_id']].drop_duplicates().iterrows():\n",
    "        situation_group = event_log[(event_log['activity'] == situation['activity']) & (event_log['case_id'] == situation['case_id'])]\n",
    "        situation_freq[situation['activity']] = len(situation_group['case_id'].unique())\n",
    "        situation_times[situation['activity']] = (situation_group['timestamp'].max() - situation_group['timestamp'].min()) / situation_freq[situation['activity']]\n",
    "    \n",
    "    # Calcular a média dos tempos em horas\n",
    "    total_time_hours = sum(action_times.values(), pd.Timedelta(0)).total_seconds() / 3600\n",
    "    num_actions = len(action_times)\n",
    "    if num_actions != 0:\n",
    "        average_time_hours = total_time_hours / num_actions\n",
    "    else:\n",
    "        average_time_hours = 0\n",
    "    \n",
    "    # Descobrir o modelo de processo usando o algoritmo Alpha Miner\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    net, initial_marking, final_marking = pm4py.discover_petri_net_alpha(event_log)\n",
    "    \n",
    "    # Criar um objeto Digraph do Graphviz\n",
    "    dot = Digraph(comment='Process Mining', format='png')\n",
    "    \n",
    "    # Adicionar nós ao grafo\n",
    "    for p in net.places:\n",
    "        if p.name in situation_times:\n",
    "            # Adicionar frequência e tempo médio como rótulo do nó\n",
    "            if situation_times[p.name] >= pd.Timedelta(days=1):\n",
    "                label = f\"{p.name} (Freq.: {situation_freq[p.name]}, Tempo médio: {situation_times[p.name].days:.1f} dias)\"\n",
    "            else:\n",
    "                label = f\"{p.name} (Freq.: {situation_freq[p.name]}, Tempo médio: {situation_times[p.name].seconds / 3600:.1f} horas)\"\n",
    "        else:\n",
    "            label = p.name\n",
    "\n",
    "        if p.name == \"start\":\n",
    "            dot.node(p.name, label=label, style=\"filled\", fillcolor=\"green\")\n",
    "        elif p.name == \"end\":\n",
    "            dot.node(p.name, label=label, style=\"filled\", fillcolor=\"green\")\n",
    "        else:\n",
    "            dot.node(p.name, label=label)\n",
    "\n",
    "    dot.edge(\"start\", list(net.transitions)[0].name, style=\"invis\")\n",
    "    dot.edge(list(net.transitions)[-1].name, \"end\", style=\"invis\")\n",
    "    \n",
    "    # Adicionar transições ao grafo\n",
    "    for t in net.transitions:\n",
    "        if t.name in action_times:\n",
    "            label = f\"{t.name}\\nFreq.: {action_freq[t.name]}\\nTempo médio: {action_times[t.name].seconds / 3600:.1f} horas\"\n",
    "        else:\n",
    "            label = t.name\n",
    "\n",
    "        dot.node(t.name, label=label, shape='rectangle', style='filled', fillcolor='lightblue')\n",
    "    \n",
    "    # Adicionar arestas ao grafo\n",
    "    for arc in net.arcs:\n",
    "        dot.edge(arc.source.name, arc.target.name)\n",
    "       \n",
    "    # Decide and Examine Casually\n",
    "    if \"decide\" in net.transitions and \"examine casually\" in net.transitions:\n",
    "        dot.edge(\"decide\", \"examine casually\", label=\"70%\", constraint=\"false\")\n",
    "        dot.edge(\"decide\", \"reject request\", label=\"30%\", constraint=\"false\")\n",
    "        dot.edge(\"reject request\", \"examine casually\", constraint=\"false\")\n",
    "\n",
    "    # Add nodes for decision-making\n",
    "    dot.node(\"decide\", label=\"decide\")\n",
    "    dot.node(\"reject request\", label=\"reject request\")\n",
    "\n",
    "    # Pay compensation\n",
    "    if \"pay compensation\" in net.transitions:\n",
    "        dot.node(\"pay compensation\", label=\"pay compensation\")\n",
    "        dot.edge(\"reject request\", \"pay compensation\")\n",
    "\n",
    "    # Reinitiate request\n",
    "    if \"reinitiate request\" in net.transitions:\n",
    "        dot.node(\"reinitiate request\", label=\"reinitiate request\")\n",
    "        dot.edge(\"pay compensation\", \"reinitiate request\")\n",
    "        dot.edge(\"decide\", \"reinitiate request\")\n",
    "\n",
    "    # Salvar o gráfico em um arquivo\n",
    "    dot.render('process_graph', format='png', cleanup=True)\n",
    "    print(\"Process graph saved as 'process_graph.png'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"Y:\\\\git\\\\Process Mining\\\\grupo-2\\\\Bases_de_Dados\\\\running-example_3.csv\"\n",
    "    import_csv(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
