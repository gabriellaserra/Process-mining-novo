{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASES NT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenação das bases de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas\n",
    "\n",
    "# Carrega os DataFrames dos arquivos Excel de 2022 e 2023\n",
    "df22 = pd.read_excel('c:\\\\Users\\\\caiobarreto\\\\Downloads\\\\Relatório_NT_2022.xlsx')\n",
    "df23 = pd.read_excel('c:\\\\Users\\\\caiobarreto\\\\Downloads\\\\Relatório_NT_2023.xlsx')\n",
    "# Concatena os DataFrames\n",
    "df = pd.concat([df22, df23])\n",
    "# Define o caminho do arquivo de saída para o DataFrame concatenado\n",
    "saida = 'c:\\\\Users\\\\caiobarreto\\\\Downloads\\\\Relatório_NT_Concatenado.xlsx'\n",
    "# Salva o DataFrame concatenado em um novo arquivo Excel\n",
    "df.to_excel(saida, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirar acentos e ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "# Remover acentos e caracteres especiais de todas as colunas\n",
    "df = df.apply(lambda x: x.map(lambda y: unidecode(str(y)) if isinstance(y, str) else y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ele utiliza a função apply para aplicar uma função lambda a cada coluna do DataFrame, e dentro dessa função lambda, utiliza outra função lambda para percorrer cada valor da coluna e remover a acentuação, caso o valor seja uma string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronizar formato de data e hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizar o formato de data e hora\n",
    "formatar = ['Data Prevista de Chegada', 'Data Prevista de Saída', \n",
    "'H.O.C.', 'Amarração','Início de Bombeio', 'Fim de Bombeio', 'Desamarração', 'H.O.S.', 'Início Primeira Amarração','Fim Primeira Amarração','Início Primeira Conexão','Fim Primeira Conexão',\n",
    "'Início Primeiro Bombeio','Fim Último Bombeio','Início Última Desconexão','Fim Última Desconexão','Início Última Desamarração','Fim Última Desamarração']\n",
    "\n",
    "for coluna in formatar:\n",
    "    df[coluna] = pandas.to_datetime(df[coluna], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remover colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as colunas, inplace é pra não precisar reatribuir e axis 1 serve pra dizer que se trata de uma coluna\n",
    "df.drop(['Classe do Navio', 'Rebocador', 'Hora Top', 'Alívio Crítico', 'Apuração Alívio Crítico', 'Volume Acumulado Perdas', 'Lifter'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tirar duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove as duplicatas\n",
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando coluna ID e adicionando valor ao indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinir o índice do DataFrame\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# Adicionando a coluna\n",
    "df.insert(0,'ID',range(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando coluna UEP e trocando Petrobras por P-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a coluna UEP e pegando o valor da coluna Instalação Naval\n",
    "df.insert(2, 'UEP', df['Instalação Naval'].str.replace('PETROBRAS', 'P-', regex=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirar os espaços em branco antes e no fim das colunas UEP e Navio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover espaços em branco antes e depois dos nomes nas colunas UEP e Navio\n",
    "df['UEP'] = df['UEP'].str.strip()\n",
    "df['Navio'] = df['Navio'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformar H.O.C em data prevista de chegada quando a diferença for >= 48 horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a diferença em horas entre as datas previstas de chegada e o H.O.C\n",
    "diferenca_horas = (df['Data Prevista de Chegada'] - df['H.O.C.']).dt.total_seconds() / 3600\n",
    "\n",
    "# Substituindo os valores de \"H.O.C\" onde a diferença for maior do que 48 horas (2 dias)\n",
    "df.loc[diferenca_horas >= 48, 'H.O.C.'] = df['Data Prevista de Chegada']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tirar duplicatas dos casos que possuem mesmo HOC, Instalação Naval e Navio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover duplicatas baseadas em \"H.O.C\", \"Instalação Naval\" e \"Navio\"\n",
    "df.drop_duplicates(subset=['H.O.C.', 'Instalação Naval', 'Navio'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTERANDO O FORMATO DA BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as colunas necessárias para alteração no formato do dataframe\n",
    "nt_colunas = ['ID', 'H.O.C.', 'Início Primeira Amarração', 'Fim Primeira Amarração', 'Início Primeira Conexão', 'Fim Primeira Conexão', 'Início Primeiro Bombeio','Fim Último Bombeio', 'Início Última Desconexão', 'Fim Última Desconexão','Início Última Desamarração', 'Fim Última Desamarração', 'H.O.S.']\n",
    "\n",
    "# Selecionar e definir as colunas que serão alteradas\n",
    "colunas_alteradas = ['H.O.C.', 'Início Primeira Amarração', 'Fim Primeira Amarração','Início Primeira Conexão', 'Fim Primeira Conexão', 'Início Primeiro Bombeio','Fim Último Bombeio', 'Início Última Desconexão', 'Fim Última Desconexão','Início Última Desconexão', 'Fim Última Desconexão', 'Início Última Desamarração','Fim Última Desamarração', 'H.O.S.']\n",
    "# Usar o método melt para transformar as colunas em registros\n",
    "df_transformado = pd.melt(df[nt_colunas], id_vars=['ID'], value_vars=colunas_alteradas, var_name='Ocorrência', value_name='Data')\n",
    "# Selecionar apenas as colunas necessárias para a junção\n",
    "colunas_restauradas = ['ID', 'Unidade Operativa', 'UEP', 'Navio', 'Volume Programado','Volume Retirado', 'Viagem', 'Destino', 'Data Prevista de Chegada','Data Prevista de Saída']\n",
    "# Realizar a junção dos DataFrames usando a coluna 'ID' como chave\n",
    "df_final = pd.merge(df[colunas_restauradas], df_transformado, on='ID', how='right')\n",
    "# Atualizar os valores da coluna 'ID' com os valores do índice\n",
    "df_final['ID'] = df_final.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.melt() é usado para transformar as colunas selecionadas em registros. O argumento id_vars=['ID'] indica quais colunas manter como identificadores, enquanto value_vars=colunas_alteradas especifica quais colunas devem ser transformadas em registros. As colunas \"Ocorrência\" e \"Data\" são os nomes das novas colunas geradas durante a transformação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenar a base por ID e Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar o DataFrame final por 'ID' e 'Data'\n",
    "df_final = df_final.sort_values(by=['ID', 'Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionar os respectivos valores às colunas ‘Início’ e ‘Término’ de cada ocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar as colunas 'Início' e 'Término' com base nas datas da ocorrência e da próxima ocorrência para o mesmo ID\n",
    "df_final['Início'] = df_final['Data']\n",
    "# Obter o valor da próxima linha na coluna \"Início\"\n",
    "df_final['Término'] = df_final['Início'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluir as colunas com “Ocorrência” = ”Fim”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar as linhas em que a \"Ocorrência\" contém a palavra \"Fim\" e obter seus índices\n",
    "indices_para_remover = df_final[df_final['Ocorrência'].str.contains('Fim')].index\n",
    "# Remover as linhas correspondentes aos índices obtidos\n",
    "df_final.drop(indices_para_remover, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renomear as colunas de Início "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirar a palavra Início da ocorrência\n",
    "df_final['Ocorrência'] = df_final['Ocorrência'].str.replace('Início ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remover a coluna data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as colunas, inplace é pra não precisar reatribuir e axis 1 serve pra dizer que se trata de uma coluna\n",
    "df_final.drop(['Data'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASE INTERRUPÇÕES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar Base Interrupções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInt = pd.read_excel(\"c:\\\\Users\\\\caiobarreto\\\\Downloads\\\\eventos_operacoes_interrupcoes2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar somente as que tiveram interrupções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar apenas as linhas em que 'Duração Interrupção' é maior que zero e reatribuir ao DataFrame dfInt\n",
    "dfInt = dfInt[dfInt['Duração Interrupção'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando Acento e Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInt = dfInt.apply(lambda x: x.map(lambda y: unidecode(str(y)) if isinstance(y, str) else y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando coluna UEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a coluna UEP \n",
    "dfInt.insert(2, 'UEP', dfInt['INNA_SG_INSTALACAO_NAVAL'].str.replace('PETROBRAS', 'P-', regex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alterando nomes das categorias da coluna UEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz um dicionário com os nomes a serem mudados na UEP\n",
    "trocaNomes = {\n",
    "    'FPBAR': 'FPSO Almirante Barroso',\n",
    "    'FPCGZ': 'FPSO Campos dos Goytacases MV29',\n",
    "    'CAPX': 'FPSO Capixaba',\n",
    "    'FPCRC': 'FPSO CARIOCA MV30',\n",
    "    'FPNIT': 'FPSO Cid. Niteroi MV18',\n",
    "    'CDAN': 'FPSO Cidade de Anchieta',\n",
    "    'FPCAR': 'FPSO Cidade de Angra Reis MV22',\n",
    "    'FPCIB': 'FPSO Cidade de Ilhabela',\n",
    "    'FPCMB': 'FPSO Cidade de Mangaratiba MV24',\n",
    "    'FPCIG': 'FPSO Cidade de Itaguai MV26',\n",
    "    'FPCMC': 'FPSO Cidade de Marica',\n",
    "    'FPCPY': 'FPSO Cidade de Paraty',\n",
    "    'FPCST': 'FPSO Cidade de Santos MV20',\n",
    "    'FPCSQ': 'FPSO Cidade de Saquarema',\n",
    "    'FPCSP': 'FPSO Cidade Sao Paulo MV23',\n",
    "    'FPGNB': 'FPSO Guanabara - MV31',\n",
    "    'FPPLB': 'FPSO Pioneiro de Libra',\n",
    "    'FSME': 'FSO Cidade de Macae - MV15'\n",
    "}\n",
    "\n",
    "# Faz a troca dos nomes da UEP utilizando o replace\n",
    "dfInt['UEP'] = dfInt['UEP'].replace(trocaNomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renomear as colunas para ficar com a mesma nomenclatura que a base NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o dicionário para renomear as colunas\n",
    "nomeColunas = {\n",
    "    'OPOF_CD_VIAGEM': 'Viagem',\n",
    "    'OPOF_NM_NAVIO': 'Navio',\n",
    "    'OPOF_NM_DESTINO': 'Destino',\n",
    "    'EOOF_IN_TIPO': 'TIPO_INTERRUPCAO',\n",
    "    'Duração Interrupção': 'DURACAO_INTERRUPCAO',\n",
    "    'EOOF_DT_REALIZADA': 'INICIO_INTERRUPCAO',\n",
    "    'EOOF_DT_FIM': 'FIM_INTERRUPCAO',\n",
    "    'OPOF_DT_ENTRADA_PREVISTA': 'Data Prevista de Chegada',\n",
    "    'OPOF_DT_SAIDA_PREVISTA': 'Data Prevista de Saída'\n",
    "}\n",
    "\n",
    "# Renomeando as colunas conforme o dicionário \n",
    "dfInt.rename(columns=nomeColunas, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirar o espaço do inicio e final das colunas Navio e UEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover espaços em branco antes e depois dos nomes nas colunas UEP e Navio\n",
    "dfInt['UEP'] = dfInt['UEP'].str.strip()\n",
    "dfInt['Navio'] = dfInt['Navio'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionar apenas as colunas que interessam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as colunas necessárias do DataFrame dfInt\n",
    "colunasSel = dfInt[['UEP', 'Viagem', 'Navio', 'Destino', 'TIPO_INTERRUPCAO', 'DURACAO_INTERRUPCAO', 'INICIO_INTERRUPCAO', 'FIM_INTERRUPCAO', 'Data Prevista de Chegada', 'Data Prevista de Saída']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JUNTAR BASE DE INTERRUPÇÕES COM A DE NAVIO TANQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Unidade Operativa</th>\n",
       "      <th>UEP</th>\n",
       "      <th>Navio</th>\n",
       "      <th>Volume Programado</th>\n",
       "      <th>Volume Retirado</th>\n",
       "      <th>Viagem</th>\n",
       "      <th>Destino</th>\n",
       "      <th>Data Prevista de Chegada</th>\n",
       "      <th>Data Prevista de Saída</th>\n",
       "      <th>Ocorrência</th>\n",
       "      <th>Início</th>\n",
       "      <th>Término</th>\n",
       "      <th>TIPO_INTERRUPCAO</th>\n",
       "      <th>DURACAO_INTERRUPCAO</th>\n",
       "      <th>INICIO_INTERRUPCAO</th>\n",
       "      <th>FIM_INTERRUPCAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>UN-BS</td>\n",
       "      <td>P- 67</td>\n",
       "      <td>FORTALEZA KNUTSEN</td>\n",
       "      <td>80000</td>\n",
       "      <td>81382.81</td>\n",
       "      <td>423 TA</td>\n",
       "      <td>T.B.N.</td>\n",
       "      <td>2022-04-27 12:00:00</td>\n",
       "      <td>2022-04-28 09:30:00</td>\n",
       "      <td>H.O.C.</td>\n",
       "      <td>2022-04-27 03:00:00</td>\n",
       "      <td>2022-07-25 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BUZIOS</td>\n",
       "      <td>P- 77</td>\n",
       "      <td>EAGLE PAULINIA</td>\n",
       "      <td>80000</td>\n",
       "      <td>81704.09</td>\n",
       "      <td>102 TA</td>\n",
       "      <td>T.B.N.</td>\n",
       "      <td>2022-07-25 12:00:00</td>\n",
       "      <td>2022-07-26 12:30:00</td>\n",
       "      <td>H.O.C.</td>\n",
       "      <td>2022-07-25 12:00:00</td>\n",
       "      <td>2022-05-11 08:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UN-BS</td>\n",
       "      <td>FPSO Cidade de Saquarema</td>\n",
       "      <td>DAN SABIA</td>\n",
       "      <td>60000</td>\n",
       "      <td>58883.00</td>\n",
       "      <td>315 TA</td>\n",
       "      <td>T.B.N.</td>\n",
       "      <td>2022-05-11 12:00:00</td>\n",
       "      <td>2022-05-12 11:00:00</td>\n",
       "      <td>H.O.C.</td>\n",
       "      <td>2022-05-11 08:30:00</td>\n",
       "      <td>2022-05-11 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>UN-ES</td>\n",
       "      <td>FSO Cidade de Macae - MV15</td>\n",
       "      <td>TOVE KNUTSEN</td>\n",
       "      <td>80000</td>\n",
       "      <td>79486.66</td>\n",
       "      <td>-</td>\n",
       "      <td>CARGA EQUINOR</td>\n",
       "      <td>2022-05-11 14:00:00</td>\n",
       "      <td>2022-05-12 16:00:00</td>\n",
       "      <td>H.O.C.</td>\n",
       "      <td>2022-05-11 06:00:00</td>\n",
       "      <td>2022-05-11 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>UN-BS</td>\n",
       "      <td>FPSO Cidade de Ilhabela</td>\n",
       "      <td>EAGLE CAMPOS</td>\n",
       "      <td>79100</td>\n",
       "      <td>79165.00</td>\n",
       "      <td>SH121</td>\n",
       "      <td>CARGA SHELL</td>\n",
       "      <td>2022-05-11 00:00:00</td>\n",
       "      <td>2022-05-12 12:18:00</td>\n",
       "      <td>H.O.C.</td>\n",
       "      <td>2022-05-11 06:00:00</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22661</th>\n",
       "      <td>38647</td>\n",
       "      <td>UN-BS</td>\n",
       "      <td>P- 66</td>\n",
       "      <td>NT LISBOA</td>\n",
       "      <td>76000</td>\n",
       "      <td>76781.44</td>\n",
       "      <td>PG043</td>\n",
       "      <td>CARGA PETROGAL</td>\n",
       "      <td>2023-07-31 00:00:00</td>\n",
       "      <td>2023-08-01 04:06:00</td>\n",
       "      <td>H.O.S.</td>\n",
       "      <td>2023-08-01 04:06:00</td>\n",
       "      <td>2023-08-01 15:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22662</th>\n",
       "      <td>38648</td>\n",
       "      <td>UN-ES</td>\n",
       "      <td>FSO Cidade de Macae - MV15</td>\n",
       "      <td>EAGLE CAMBE</td>\n",
       "      <td>151000</td>\n",
       "      <td>154121.00</td>\n",
       "      <td>055 TA</td>\n",
       "      <td>T.B.N.</td>\n",
       "      <td>2023-07-31 03:01:00</td>\n",
       "      <td>2023-08-01 15:23:45</td>\n",
       "      <td>H.O.S.</td>\n",
       "      <td>2023-08-01 15:55:00</td>\n",
       "      <td>2023-08-01 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22663</th>\n",
       "      <td>38649</td>\n",
       "      <td>UN-ES</td>\n",
       "      <td>P- 58</td>\n",
       "      <td>ANGRA DOS REIS</td>\n",
       "      <td>70000</td>\n",
       "      <td>71039.00</td>\n",
       "      <td>429 TA</td>\n",
       "      <td>T.B.N.</td>\n",
       "      <td>2023-07-31 08:00:00</td>\n",
       "      <td>2023-08-01 16:00:00</td>\n",
       "      <td>H.O.S.</td>\n",
       "      <td>2023-08-01 16:00:00</td>\n",
       "      <td>2023-08-01 16:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22664</th>\n",
       "      <td>38650</td>\n",
       "      <td>UN-BS</td>\n",
       "      <td>FPSO Cidade de Marica</td>\n",
       "      <td>EAGLE PAULINIA</td>\n",
       "      <td>155000</td>\n",
       "      <td>150823.66</td>\n",
       "      <td>155 TA</td>\n",
       "      <td>T.B.N.</td>\n",
       "      <td>2023-07-31 08:00:00</td>\n",
       "      <td>2023-08-01 16:55:00</td>\n",
       "      <td>H.O.S.</td>\n",
       "      <td>2023-08-01 16:55:00</td>\n",
       "      <td>2023-08-01 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22665</th>\n",
       "      <td>38651</td>\n",
       "      <td>UN-BUZ</td>\n",
       "      <td>P- 76</td>\n",
       "      <td>ELKA LEBLON</td>\n",
       "      <td>80000</td>\n",
       "      <td>81372.15</td>\n",
       "      <td>402 TA</td>\n",
       "      <td>T.B.N.</td>\n",
       "      <td>2023-07-31 13:00:00</td>\n",
       "      <td>2023-08-01 18:00:00</td>\n",
       "      <td>H.O.S.</td>\n",
       "      <td>2023-08-01 18:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22666 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Unidade Operativa                         UEP              Navio  \\\n",
       "0          0             UN-BS                       P- 67  FORTALEZA KNUTSEN   \n",
       "1          1            BUZIOS                       P- 77     EAGLE PAULINIA   \n",
       "2          2             UN-BS    FPSO Cidade de Saquarema          DAN SABIA   \n",
       "3          3             UN-ES  FSO Cidade de Macae - MV15       TOVE KNUTSEN   \n",
       "4          4             UN-BS     FPSO Cidade de Ilhabela       EAGLE CAMPOS   \n",
       "...      ...               ...                         ...                ...   \n",
       "22661  38647             UN-BS                       P- 66          NT LISBOA   \n",
       "22662  38648             UN-ES  FSO Cidade de Macae - MV15        EAGLE CAMBE   \n",
       "22663  38649             UN-ES                       P- 58     ANGRA DOS REIS   \n",
       "22664  38650             UN-BS       FPSO Cidade de Marica     EAGLE PAULINIA   \n",
       "22665  38651            UN-BUZ                       P- 76        ELKA LEBLON   \n",
       "\n",
       "       Volume Programado  Volume Retirado  Viagem         Destino  \\\n",
       "0                  80000         81382.81  423 TA          T.B.N.   \n",
       "1                  80000         81704.09  102 TA          T.B.N.   \n",
       "2                  60000         58883.00  315 TA          T.B.N.   \n",
       "3                  80000         79486.66       -   CARGA EQUINOR   \n",
       "4                  79100         79165.00   SH121     CARGA SHELL   \n",
       "...                  ...              ...     ...             ...   \n",
       "22661              76000         76781.44   PG043  CARGA PETROGAL   \n",
       "22662             151000        154121.00  055 TA          T.B.N.   \n",
       "22663              70000         71039.00  429 TA          T.B.N.   \n",
       "22664             155000        150823.66  155 TA          T.B.N.   \n",
       "22665              80000         81372.15  402 TA          T.B.N.   \n",
       "\n",
       "      Data Prevista de Chegada Data Prevista de Saída Ocorrência  \\\n",
       "0          2022-04-27 12:00:00    2022-04-28 09:30:00     H.O.C.   \n",
       "1          2022-07-25 12:00:00    2022-07-26 12:30:00     H.O.C.   \n",
       "2          2022-05-11 12:00:00    2022-05-12 11:00:00     H.O.C.   \n",
       "3          2022-05-11 14:00:00    2022-05-12 16:00:00     H.O.C.   \n",
       "4          2022-05-11 00:00:00    2022-05-12 12:18:00     H.O.C.   \n",
       "...                        ...                    ...        ...   \n",
       "22661      2023-07-31 00:00:00    2023-08-01 04:06:00     H.O.S.   \n",
       "22662      2023-07-31 03:01:00    2023-08-01 15:23:45     H.O.S.   \n",
       "22663      2023-07-31 08:00:00    2023-08-01 16:00:00     H.O.S.   \n",
       "22664      2023-07-31 08:00:00    2023-08-01 16:55:00     H.O.S.   \n",
       "22665      2023-07-31 13:00:00    2023-08-01 18:00:00     H.O.S.   \n",
       "\n",
       "                   Início             Término TIPO_INTERRUPCAO  \\\n",
       "0     2022-04-27 03:00:00 2022-07-25 12:00:00              NaN   \n",
       "1     2022-07-25 12:00:00 2022-05-11 08:30:00              NaN   \n",
       "2     2022-05-11 08:30:00 2022-05-11 06:00:00              NaN   \n",
       "3     2022-05-11 06:00:00 2022-05-11 06:00:00              NaN   \n",
       "4     2022-05-11 06:00:00 2022-01-01 02:00:00              NaN   \n",
       "...                   ...                 ...              ...   \n",
       "22661 2023-08-01 04:06:00 2023-08-01 15:55:00              NaN   \n",
       "22662 2023-08-01 15:55:00 2023-08-01 16:00:00              NaN   \n",
       "22663 2023-08-01 16:00:00 2023-08-01 16:55:00              NaN   \n",
       "22664 2023-08-01 16:55:00 2023-08-01 18:00:00              NaN   \n",
       "22665 2023-08-01 18:00:00                 NaT              NaN   \n",
       "\n",
       "       DURACAO_INTERRUPCAO INICIO_INTERRUPCAO FIM_INTERRUPCAO  \n",
       "0                      NaN                NaT             NaT  \n",
       "1                      NaN                NaT             NaT  \n",
       "2                      NaN                NaT             NaT  \n",
       "3                      NaN                NaT             NaT  \n",
       "4                      NaN                NaT             NaT  \n",
       "...                    ...                ...             ...  \n",
       "22661                  NaN                NaT             NaT  \n",
       "22662                  NaN                NaT             NaT  \n",
       "22663                  NaN                NaT             NaT  \n",
       "22664                  NaN                NaT             NaT  \n",
       "22665                  NaN                NaT             NaT  \n",
       "\n",
       "[22666 rows x 17 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Junção das bases de interrupções e NT\n",
    "dfUni = pd.merge(df_final, colunasSel, on=['UEP', 'Viagem', 'Navio', 'Destino', 'Data Prevista de Chegada', 'Data Prevista de Saída'], how='left')\n",
    "dfUni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restringir as características de interrupção apenas aos bombeios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir valor da coluna 'TIPO_INTERRUPCAO' por 'Interrupção Bombeio' onde 'Ocorrência' contém 'Bombeio' e 'TIPO_INTERRUPCAO' = 'B005', caso contrário, substituir por ''\n",
    "condicao_1 = (dfUni['Ocorrência'].str.contains('Bombeio')) & (dfUni['TIPO_INTERRUPCAO'] == 'B005')\n",
    "dfUni.loc[condicao_1, 'TIPO_INTERRUPCAO'] = 'Interrupção Bombeio'\n",
    "dfUni.loc[~condicao_1, 'TIPO_INTERRUPCAO'] = ''\n",
    "\n",
    "# Manter valor da coluna 'DURACAO_INTERRUPCAO' onde 'Ocorrência' contém 'Bombeio' e 'DURACAO_INTERRUPCAO' > 0\n",
    "condicao_2 = (dfUni['Ocorrência'].str.contains('Bombeio')) & (dfUni['DURACAO_INTERRUPCAO'] > 0)\n",
    "dfUni.loc[condicao_2, 'DURACAO_INTERRUPCAO'] = dfUni.loc[condicao_2, 'DURACAO_INTERRUPCAO']\n",
    "dfUni.loc[~condicao_2, 'TIPO_INTERRUPCAO'] = ''\n",
    "\n",
    "# Manter valor da coluna 'INICIO_INTERRUPCAO' onde 'Ocorrência' contém 'Bombeio' e 'TIPO_INTERRUPCAO' = 'Interrupção Bombeio'\n",
    "condicao_3 = (dfUni['Ocorrência'].str.contains('Bombeio')) & (dfUni['TIPO_INTERRUPCAO'] == 'Interrupção Bombeio')\n",
    "dfUni.loc[condicao_3, 'INICIO_INTERRUPCAO'] = dfUni.loc[condicao_3, 'INICIO_INTERRUPCAO']\n",
    "dfUni.loc[~condicao_3, 'TIPO_INTERRUPCAO'] = ''\n",
    "\n",
    "# Manter valor da coluna 'FIM_INTERRUPCAO' onde 'Ocorrência' contém 'Bombeio' e 'TIPO_INTERRUPCAO' = 'Interrupção Bombeio'\n",
    "condicao_4 = (dfUni['Ocorrência'].str.contains('Bombeio')) & (dfUni['TIPO_INTERRUPCAO'] == 'Interrupção Bombeio')\n",
    "dfUni.loc[condicao_4, 'FIM_INTERRUPCAO'] = dfUni.loc[condicao_4, 'FIM_INTERRUPCAO']\n",
    "dfUni.loc[~condicao_4, 'TIPO_INTERRUPCAO'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retirar duplicatas coluna Unnamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUni = dfUni.drop_duplicates(subset=dfUni.columns[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicas as linhas em que acontece as interrupções e resetar os índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenar por ID e Início"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se o inicio da interrupção for antes do bombeio, substituir o valor de inicio da interrupção pelo valor de inicio do bombeio, o mesmo acontece para as datas de fim, se o fim da interrupção for depois do fim do bombeio, substituir o fim da interrupção com o valor de fim do bombeio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Verificar se TIPO_INTERRUPCAO está vazio e substituir os valores das outras colunas\n",
    "condicao = dfUni['TIPO_INTERRUPCAO'] == ''\n",
    "dfUni.loc[condicao, ['DURACAO_INTERRUPCAO', 'INICIO_INTERRUPCAO', 'FIM_INTERRUPCAO']] = np.nan\n",
    "\n",
    "# Substituir o início da interrupção pelo valor de início do bombeio onde necessário\n",
    "dfUni.loc[dfUni['INICIO_INTERRUPCAO'] < dfUni['Início'], 'INICIO_INTERRUPCAO'] = dfUni['Início']\n",
    "\n",
    "# Substituir o fim da interrupção pelo valor de fim do bombeio onde necessário\n",
    "dfUni.loc[dfUni['FIM_INTERRUPCAO'] > dfUni['Término'], 'FIM_INTERRUPCAO'] = dfUni['Término']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alterar as datas de término da primeira interrupção e início da segunda interrupção dentro de um mesmo id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se TIPO_INTERRUPCAO de linhas consecutivas são iguais a \"Interrupção Bombeio\"\n",
    "condicao_1 = (dfUni['TIPO_INTERRUPCAO'].shift() == 'Interrupção Bombeio') & (dfUni['TIPO_INTERRUPCAO'] == 'Interrupção Bombeio')\n",
    "# Verificar se DURACAO_INTERRUPCAO de linhas consecutivas são diferentes\n",
    "condicao_2 = (dfUni['TIPO_INTERRUPCAO'].shift() == 'Interrupção Bombeio') & (dfUni['TIPO_INTERRUPCAO'] == 'Interrupção Bombeio') & (dfUni['DURACAO_INTERRUPCAO'].shift() != dfUni['DURACAO_INTERRUPCAO'])\n",
    "# Atualizar as datas conforme as condições especificadas\n",
    "dfUni.loc[condicao_1, 'Término'] = dfUni['INICIO_INTERRUPCAO'].shift(-1)\n",
    "dfUni.loc[condicao_1, 'Início'] = dfUni['FIM_INTERRUPCAO']\n",
    "dfUni.loc[condicao_2, 'Início'] = dfUni['FIM_INTERRUPCAO']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
